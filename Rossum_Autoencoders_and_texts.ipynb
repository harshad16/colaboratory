{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Rossum Autoencoders and texts",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "uOP_zKFgK2kF"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/martinpovolny/colaboratory/blob/master/Rossum_Autoencoders_and_texts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAA6qJSIDZ79",
        "colab_type": "text"
      },
      "source": [
        "Welcome to google collab! If you are not familiar with the collab notebooks, I hope you will be positively surprised :)  \n",
        "\n",
        "Please:\n",
        "- Copy this notebook into your own drive (File->Save a copy to drive)\n",
        "- Look into this original notebook anyway you wish, it does contain our saved run\n",
        "- Run it \n",
        "  - And feel free to select Runtime->Change runtime type into a GPU accelerated workstation :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOP_zKFgK2kF",
        "colab_type": "text"
      },
      "source": [
        "# Autoencoders - quick theory and live examples\n",
        "\n",
        "![autoencoder image](https://www.researchgate.net/publication/318204554/figure/fig1/AS:512595149770752@1499223615487/Autoencoder-architecture.png)   \n",
        "(Image from https://www.researchgate.net/publication/318204554_Intelligent_condition_monitoring_method_for_bearing_faults_from_highly_compressed_measurements_using_sparse_over-complete_features/figures?lo=1)  \n",
        "\n",
        "  \n",
        "Autoencoder is a model, that (is trained to) map outputs to be as similar as inputs as possible.  \n",
        "Keys:\n",
        "- Unsupervised learning\n",
        "- The point is in the architecture, because it is not an identity function\n",
        " - But we can say identity-like with 'bottleneck'\n",
        "- has 2 parts:\n",
        " - encoder (maps input to inner representation)\n",
        " - decoder (maps inner representation to output)\n",
        "- both parts trained together to reduce input-output error\n",
        "- were used for pretraining a deeper models (as in image, each part trained alone)\n",
        "  - ![alt text](https://www.researchgate.net/profile/Francois_Pachet/publication/319524552/figure/fig21/AS:535791140708363@1504753970877/Stacked-autoencoders-architecture_W640.jpg)\n",
        "- now used for dimensionality reduction and other usecases (covered here as ecamples)  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dc6muLM_o2r4",
        "colab_type": "text"
      },
      "source": [
        "## Autoencoder live demos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjNolFi-nIML",
        "colab_type": "code",
        "outputId": "71471515-43e9-4668-d535-a4f44332c395",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        }
      },
      "source": [
        "from IPython.display import IFrame\n",
        "IFrame('https://cs.stanford.edu/people/karpathy/convnetjs/demo/autoencoder.html', width=900, height=350)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"900\"\n",
              "            height=\"350\"\n",
              "            src=\"https://cs.stanford.edu/people/karpathy/convnetjs/demo/autoencoder.html\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7fd0c1e03ba8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rn-3gwGknYnT",
        "colab_type": "code",
        "outputId": "9ade4b8c-5e92-4261-9278-8fc8329817ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        }
      },
      "source": [
        "# Not exactly an autoencoder, only when you think that the input and output are images and the bottleneck is, that it is able to use just positions.\n",
        "IFrame('https://cs.stanford.edu/people/karpathy/convnetjs/demo/image_regression.html', width=900, height=350)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"900\"\n",
              "            height=\"350\"\n",
              "            src=\"https://cs.stanford.edu/people/karpathy/convnetjs/demo/image_regression.html\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7fd0c1e03e48>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W31326syoXro",
        "colab_type": "code",
        "outputId": "bdd5a958-9ca2-4b90-e3a5-a4170e555546",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        }
      },
      "source": [
        "IFrame('https://magenta.tensorflow.org/assets/sketch_rnn_demo/multi_vae.html', width=900, height=350)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"900\"\n",
              "            height=\"350\"\n",
              "            src=\"https://magenta.tensorflow.org/assets/sketch_rnn_demo/multi_vae.html\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7fd0c1e03c50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_6uaJOloY99",
        "colab_type": "code",
        "outputId": "5e95bcdf-80ad-48bf-9365-ef0bd6744d0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "source": [
        "IFrame('https://transcranial.github.io/keras-js/#/mnist-vae', width=900, height=350)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"900\"\n",
              "            height=\"350\"\n",
              "            src=\"https://transcranial.github.io/keras-js/#/mnist-vae\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7f13fe200cc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUmgvGxrxLYc",
        "colab_type": "text"
      },
      "source": [
        "# Autoencoders and text data - Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3W4niBhfVyg",
        "colab_type": "text"
      },
      "source": [
        "### What we would like to cover:\n",
        "- Autoencoders usage on texts with word by word representation\n",
        "- **How to work with autoencoders, how to use them and analyze them. (As opposed to 'how to build an anutoencoder to reach a given goal')**\n",
        "  - we will specifically aim to use the most basic autoencoder (see image at the top)\n",
        "  - ... and do not scroll to the bottom immediately, there are spoilers :)\n",
        "    \n",
        "Note:\n",
        "- The usual flow of experimental work would be to experiment (proof of work) on training data and validate/test on testing data.\n",
        "  - Note, that here we do only experiments on training data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTMW1df_wpXV",
        "colab_type": "text"
      },
      "source": [
        "## Preparation of the environment + imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nsn616Q-wn0w",
        "colab_type": "code",
        "outputId": "d6fdf346-6ac4-4eea-f5bd-c27544503664",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!pip install bhtsne  # for visualizations with TSNE"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bhtsne\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5b/32/3e25093337ab8811e0c3ebd89ad60fd6ca19ef9d7cebb645454f2bc59eaf/bhtsne-0.1.9.tar.gz (86kB)\n",
            "\u001b[K    100% |████████████████████████████████| 92kB 7.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from bhtsne) (1.14.6)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from bhtsne) (0.29.5)\n",
            "Building wheels for collected packages: bhtsne\n",
            "  Building wheel for bhtsne (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/d3/11/da/b469506296148e4a04bb3bd5083052a2c5d44709851ed17c21\n",
            "Successfully built bhtsne\n",
            "Installing collected packages: bhtsne\n",
            "Successfully installed bhtsne-0.1.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QNksNMStB00",
        "colab_type": "code",
        "outputId": "ea101702-163e-4e29-d3fd-f564ce37288f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import unicodedata\n",
        "import sys\n",
        "import numpy as np\n",
        "import tempfile\n",
        "from six import string_types, reraise\n",
        "from copy import copy\n",
        "import os\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "from keras.layers import Input, Dense, Dropout, Flatten, Reshape\n",
        "from keras.models import Model\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import chardet\n",
        "from bhtsne import tsne  #https://github.com/dominiek/python-bhtsne\n",
        "from sklearn.cluster import Birch\n",
        "\n",
        "\n",
        "class tempmap(np.memmap):\n",
        "  \"\"\"\n",
        "  Just a helper class for memmap numpy arrays to stay in the temporary directory.\n",
        "  \"\"\"\n",
        "  def __new__(subtype, dtype=np.uint8, mode='w+', offset=0,\n",
        "              shape=None, order='C'):\n",
        "      ntf = tempfile.NamedTemporaryFile()\n",
        "      self = np.memmap.__new__(subtype, ntf, dtype, mode, offset, shape, order)\n",
        "      self.temp_file_obj = ntf\n",
        "      return self\n",
        "\n",
        "  def __del__(self):\n",
        "      if hasattr(self,'temp_file_obj') and self.temp_file_obj is not None:\n",
        "          self.temp_file_obj.close()\n",
        "          # del self.temp_file_obj"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IobMq8uywwCC",
        "colab_type": "text"
      },
      "source": [
        "## IMDB Dataset download & inspection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIdQhifghkht",
        "colab_type": "text"
      },
      "source": [
        "At this point, any dataset can be used, we have decided to use a dataset of IMDB movie reviews."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9n6CaNJthOD",
        "colab_type": "code",
        "outputId": "93e4bdd2-99b5-44dc-9f18-68387ba4bee1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "!tar xfz aclImdb_v1.tar.gz"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-02-25 07:44:43--  http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
            "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 84125825 (80M) [application/x-gzip]\n",
            "Saving to: ‘aclImdb_v1.tar.gz’\n",
            "\n",
            "aclImdb_v1.tar.gz   100%[===================>]  80.23M  19.2MB/s    in 7.3s    \n",
            "\n",
            "2019-02-25 07:44:51 (11.0 MB/s) - ‘aclImdb_v1.tar.gz’ saved [84125825/84125825]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VtNgqUUtlLb",
        "colab_type": "code",
        "outputId": "cd6a9bbe-4678-451d-d085-d30bc8f09cd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Vocabulary: Loads all words used, starting by the most frequent.\n",
        "# We need the vocabulary only for displaying the results.\n",
        "vocab_cut = 20000 # Keep only most frequent words rather than all\n",
        "\n",
        "with open('aclImdb/imdb.vocab', \"rb\") as f:\n",
        "    rawdata=f.read()\n",
        "    \n",
        "    # automatic inspect of the encoding and data, in case we forget :)\n",
        "    print(chardet.detect(rawdata))\n",
        "    f.seek(0)\n",
        "    vocab = [word.decode(\"utf8\").rstrip() for word in f]\n",
        "    \n",
        "    # Just saving memory - the long tail occurs too few times\n",
        "    # for the model to learn anything anyway\n",
        "    vocab = vocab[:vocab_cut]\n",
        "    print('%d words in vocabulary' % (len(vocab),))\n",
        "    print(type(vocab[0]))\n",
        "\n",
        "# append some number to the vocabulary (for disaplying resons, does not affect training)\n",
        "for i in range(99):\n",
        "  vocab.append(str(i))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'encoding': 'utf-8', 'confidence': 0.99, 'language': ''}\n",
            "20000 words in vocabulary\n",
            "<class 'str'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bMzDBv7xAbk",
        "colab_type": "text"
      },
      "source": [
        "## Nonautoencoder baseline and helper functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oixos7t2xrTi",
        "colab_type": "text"
      },
      "source": [
        "The text processing should employ tokenization of the text and some helper functions like deaccenting, because autoencoders (and other text procesing algorithms and models in ML) do not work with text naturally.  \n",
        "  \n",
        " Generally we have more options:  \n",
        " 1. Embedd each word into defined dimensional space by a trained embedding.\n",
        " 2. Put onehot representation of each word or character into the network\n",
        " 3. Use 'feature vectors' for each word\n",
        "   \n",
        "For our first try with ML model, lets use feature vectors.\n",
        "- the feature vector generator does not use memory as much as embeddings\n",
        "- feature vectors are 'fair' to our model, meaning that embeddings are usually pretrained and will already bear more information\n",
        "- every word has its feature vector (as opposed to the fact, that not all words have an embedding)\n",
        "- character level models can be a tiny bit harder to understand or train\n",
        "  \n",
        "Feature vector function used here ('features_from_text') is usually used for a text analysis task, because it does count the number of lowercase/uppercase letter/digits and character frequencies.  \n",
        "\n",
        "With this function we are, moreover, able to lookup back into a dictionary (will be shown)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fh_Utgy9tsKN",
        "colab_type": "code",
        "outputId": "304458d9-13fd-4d1a-cbab-ec14ba63a67f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "def text_tokens(text):\n",
        "  \"\"\"\n",
        "  Tokenization is the proces that turns a text sentence into a sequence of tokens,\n",
        "  i.e. decides what is a word and what is a separator.\n",
        "  \"\"\"  \n",
        "  text = re.sub(\"\\\\s\", \" \", text)\n",
        "  text = re.sub(\"<br/>\", \" \", text)\n",
        "  text = re.sub(\"<br />\", \" \", text)\n",
        "  text = re.sub(\"<br>\", \" \", text)\n",
        "  #text = re.sub(\"[^a-zA-Z' ]\", \"\", text)\n",
        "  tokens = re.split('(\\W+)', text) # text.split(' ')\n",
        "  tokens = [re.sub(\" \", \"\", token) for token in tokens if token not in [' ', '']]\n",
        "  return tokens\n",
        "\n",
        "# This is our vocabulary of characters we will work with, other will be forgotten\n",
        "default_char_list = u' abcdefghijklmnopqrstuvwxyz0123456789,.-+:/%?$£€#()&\\''\n",
        "default_char_vocab = {letter: i for i, letter in enumerate(list(default_char_list))}\n",
        "\n",
        "\n",
        "def remove_accents(input_str):\n",
        "  \"\"\"\n",
        "  We do not want accents and special characters, so lets normalize the text.\n",
        "  \"\"\"\n",
        "  try:\n",
        "      # variant:\n",
        "      # unicoded = unicode(input_char)\n",
        "      # # .decode('utf-8', 'ignore')\n",
        "      # nfkd_form = unicodedata.normalize('NFKD', unicoded)\n",
        "      # only_ascii = nfkd_form.encode('ASCII', 'ignore')\n",
        "      # if len(only_ascii) <= 0:\n",
        "      #    return nfkd_form\n",
        "\n",
        "      if len(input_str) == 0:\n",
        "        return u\"\"\n",
        "      unistr = input_str.replace(u'\\xf8', u'o')\n",
        "      unistr = unistr.replace(u'\\xd8', u'O')\n",
        "\n",
        "      unistr = \"\".join(aChar\n",
        "                     for aChar in unicodedata.normalize(\"NFD\", unistr)\n",
        "                     if not unicodedata.combining(aChar))\n",
        "      return unistr\n",
        "  except Exception as e:\n",
        "      print(\"at {}\".format(input_str))\n",
        "      reraise(type(e), e, sys.exc_info()[2])\n",
        "\n",
        "        \n",
        "def base_text_features(text, features=['len', 'upper', 'lower', 'alpha', 'digit'],\n",
        "                       scale=20,\n",
        "                       char_vocab=default_char_vocab):\n",
        "  \"\"\"\n",
        "  Function, that extract features from the given text based on given parameters.\n",
        "  If character vocabulary is given, the features contain character frequencies.\n",
        "  \"\"\"\n",
        "  def text_histogram(text, char_vocab=default_char_vocab,\n",
        "                     char_vocab_make_lower=True):\n",
        "      hist = [0] * len(default_char_vocab.keys())\n",
        "      for letter in text:\n",
        "          if char_vocab_make_lower:\n",
        "              luse = letter.lower()\n",
        "          else:\n",
        "              luse = letter\n",
        "          luse = remove_accents(luse)\n",
        "          if luse in default_char_vocab:\n",
        "              hist[default_char_vocab[luse]] += 1\n",
        "      return hist\n",
        "\n",
        "  def count_uppers(text):\n",
        "      return sum([letter.isupper() for letter in text])\n",
        "\n",
        "  def count_lowers(text):\n",
        "      return sum([letter.islower() for letter in text])\n",
        "\n",
        "  def count_alphas(text):\n",
        "      return sum([letter.isalpha() for letter in text])\n",
        "\n",
        "  def count_digits(text):\n",
        "      return sum([letter.isdigit() for letter in text])\n",
        "\n",
        "  use_cases = {\n",
        "      'len': len,\n",
        "      'upper': count_uppers,\n",
        "      'lower': count_lowers,\n",
        "      'alpha': count_alphas,\n",
        "      'digit': count_digits,\n",
        "  }\n",
        "  repr = [use_cases[feature](text) for feature in features]\n",
        "  if char_vocab is not None:\n",
        "      repr.extend(text_histogram(text, default_char_vocab))\n",
        "\n",
        "  if scale is not None:\n",
        "      for i in range(len(repr)):\n",
        "          repr[i] = min(repr[i] / scale, 1.0)\n",
        "\n",
        "  return repr\n",
        "\n",
        "\n",
        "def features_from_text(text, values_scales=[100.0], scale=20):\n",
        "  \"\"\"\n",
        "  Lets extract features from the whole word, beginning of a word and ending of a word.\n",
        "  (Also if the given word is a number, lets scale it into [0,1] interval;\n",
        "  this should help the network with text, that does come after a number as '1 st')\n",
        "  \"\"\"\n",
        "  try:\n",
        "      xtextasval = float(text.replace(\" \", \"\").replace(\"%\", \"\"))\n",
        "      xtextisval = 1.0\n",
        "      assert np.isfinite(xtextasval)\n",
        "  except:\n",
        "      xtextasval = 0.0\n",
        "      xtextisval = 0.0\n",
        "  if xtextisval > 0.0:  # is actually a value\n",
        "      xtextasval = [min(xtextasval / scale, 1.0) for scale in values_scales]\n",
        "  else:\n",
        "      xtextasval = [0.0] * len(values_scales)\n",
        "\n",
        "  allfeats = base_text_features(text, scale=scale, features=['len', 'upper', 'lower', 'alpha', 'digit'])\n",
        "  if len(text) <= 1:\n",
        "      # just if we use the histograms for first two letters and last two letters, what to do in smaller\n",
        "      text_to_handle = \" \" + text + \" \"\n",
        "  else:\n",
        "      text_to_handle = text\n",
        "  begfeats = base_text_features(text_to_handle[0:2], scale=scale, features=['upper', 'lower', 'alpha', 'digit'])\n",
        "  endfeats = base_text_features(text_to_handle[-2:0], scale=scale, features=['upper', 'lower', 'alpha', 'digit'])\n",
        "\n",
        "  return allfeats + begfeats + endfeats + xtextasval + [xtextisval]\n",
        "\n",
        "\n",
        "print(\"Lets test our code:\")\n",
        "print(\"Does tokenization leave a word in a vocabulary alone?: {}\".\n",
        "      format(text_tokens(vocab[1552])))\n",
        "print(u\"Word '{}' is, for example, translated as {} \".format(vocab[1552], features_from_text(vocab[1552])))\n",
        "print(u\"Words '{}' is deaccented as {}\".format(vocab[1552], remove_accents(vocab[1552])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lets test our code:\n",
            "Does tokenization leave a word in a vocabulary alone?: ['cliché']\n",
            "Word 'cliché' is, for example, translated as [0.3, 0.0, 0.3, 0.3, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.05, 0.0, 0.0, 0.05, 0.05, 0.0, 0.0, 0.05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.1, 0.0, 0.0, 0.0, 0.0, 0.05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] \n",
            "Words 'cliché' is deaccented as cliche\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BpXom_uhCHS",
        "colab_type": "text"
      },
      "source": [
        "When using any form of inner representations, we would need to have a function, that rewrites the inner representation into an existing word to be understandable for us.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zErw9LwDv5l6",
        "colab_type": "code",
        "outputId": "14e4294d-9d4f-4802-dc4d-54debda227b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "def vocab_finder(item, vocab, key_f=None, apply_on_item_too=True):\n",
        "  \"\"\"\n",
        "  A modular function to allow for searching an item against vocabulary of items\n",
        "  based on the minimal distance. \n",
        "  The modularity allows for applying a function over the vocabulary\n",
        "  or query items.\n",
        "  \"\"\"\n",
        "  if apply_on_item_too:\n",
        "      fitem = key_f(item) if key_f else item\n",
        "  else:\n",
        "      fitem = item\n",
        "  mindiff = None\n",
        "  minitem = None\n",
        "  \n",
        "  for v, vitem in enumerate(vocab):\n",
        "      fvitem = key_f(vitem) if key_f else vitem\n",
        "      \n",
        "      diff = np.mean(np.square(np.asarray(fitem) - np.asarray(fvitem)))        \n",
        "      if mindiff is None or diff < mindiff:\n",
        "          mindiff = diff\n",
        "          minitem = (v, vitem)\n",
        "  return minitem, mindiff\n",
        "\n",
        "\n",
        "print(\"A test that/how the vocabulary search works: \\n\")\n",
        "print(vocab_finder(\"the\", vocab, features_from_text))\n",
        "print(vocab_finder(\"nonsensualword\", vocab, features_from_text))\n",
        "print(vocab_finder(\"potential\", vocab, features_from_text))\n",
        "print(\"\")\n",
        "print(\"Idea: Try to think about the feature vector as a hash and find collisions in the provided hashing over the vocabulary\")\n",
        "print(\"Idea: Try the code with bigger/smaller vocabulary\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A test that/how the vocabulary search works: \n",
            "\n",
            "((0, 'the'), 0.0)\n",
            "((15379, 'unprofessional'), 0.0001149425287356322)\n",
            "((948, 'potential'), 0.0)\n",
            "\n",
            "Idea: Try to think about the feature vector as a hash and find collisions in the provided hashing over the vocabulary\n",
            "Idea: Try the code with bigger/smaller vocabulary\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFV-kb6xxmOV",
        "colab_type": "text"
      },
      "source": [
        "## Dataset preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B51wG17j0NjS",
        "colab_type": "text"
      },
      "source": [
        "We will load a small subset of the dataset (can be increased for speed tradeoff :) )  and process it together with vocabulary with our feature vectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYh-LIFRv9Ad",
        "colab_type": "code",
        "outputId": "beaef5f9-66e5-4588-b800-6cdda8987f9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "def load_dataset(dirname, train_set_slice_size=5000):\n",
        "  \"\"\"\n",
        "  Loads and tokenizes a dataset into a list.\n",
        "  Label loading included, even though we will not use it for autoencoders.\n",
        "  Set train_set_slice_size to 500 for fast tryout.\n",
        "  \"\"\"\n",
        "  X, y = [], []\n",
        "  # Review files: neg/0_3.txt neg/10000_4.txt neg/10001_4.txt ...\n",
        "  for y_val, y_label in enumerate(['neg', 'pos']):\n",
        "      y_dir = os.path.join(dirname, y_label)\n",
        "      for fname in os.listdir(y_dir):\n",
        "          fpath = os.path.join(y_dir, fname)\n",
        "          with open(fpath) as f:\n",
        "              tokens = text_tokens(f.read())            \n",
        "          X.append(tokens)            \n",
        "          y.append(y_val)  # 0 for 'neg', 1 for 'pos'\n",
        "\n",
        "          if len(X) >= train_set_slice_size:\n",
        "            break\n",
        "      if len(X) >= train_set_slice_size:\n",
        "        break\n",
        "  return X, y\n",
        "\n",
        "print(\"loading dataset\")\n",
        "X_train_orig, y_train = load_dataset('aclImdb/train/')\n",
        "print(\"The loaded dataset has length {} \\n sample tokenized sentence from dataset is: {}\"\n",
        "      .format(len(X_train_orig), X_train_orig[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading dataset\n",
            "The loaded dataset has length 5000 \n",
            " sample tokenized sentence from dataset is: ['The', 'basic', 'plot', 'in', 'this', 'movie', 'isn', \"'\", 't', 'bad', '.', 'A', 'lady', 'makes', 'it', 'big', 'and', 'comes', 'back', 'to', 'her', 'alma', 'mater', 'to', 'be', 'adored', '.', 'But', ',', 'despite', 'good', 'acting', 'by', 'Robert', 'Young', 'and', 'Eve', 'Arden', ',', 'the', 'movie', 'is', 'a', 'mess', '.', 'The', 'blame', 'for', 'this', 'I', 'place', 'on', 'either', 'Joan', 'Crawford', 'or', 'the', 'director', 'or', 'both', ',', 'as', 'her', 'performance', 'is', 'just', 'awful', '.', 'Instead', 'of', 'being', 'a', 'real', 'person', ',', 'she', 'does', 'a', 'wonderful', 'impersonation', 'of', 'a', 'deer', 'caught', 'in', 'the', 'headlights', '.', 'In', 'other', 'words', ',', 'she', 'stares', 'off', 'into', 'space', 'and', 'has', 'a', '\"', 'golly', 'I', 'am', 'SOOOO', 'stunned', '\"', 'expression', '.', 'After', 'just', 'a', 'few', 'minutes', 'it', 'really', 'became', 'annoying', 'for', 'me', '.', 'Now', 'this', 'is', 'certainly', 'not', 'the', 'only', 'Crawford', 'film', 'I', 'dislike', 'for', 'her', 'performance', ',', 'as', 'she', 'had', 'done', 'more', 'than', 'her', 'share', 'of', 'overacting', '--', 'in', 'films', 'such', 'as', 'JOHNNY', 'GUITAR', 'or', 'many', 'of', 'her', 'later', 'films', ',', 'such', 'as', 'BERSERK', '!', 'My', 'advice', 'is', 'to', 'try', 'a', 'different', 'Crawford', 'film', '--', 'there', 'certainly', 'were', 'better', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFYhYBGWv_wh",
        "colab_type": "code",
        "outputId": "3ec89f21-183a-4300-e506-b9b5134cdda7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "def prepare_dataset_with_embeddings(vocab,\n",
        "                                    embedd_f=features_from_text,\n",
        "                                    X_train=X_train_orig):\n",
        "  \"\"\"\n",
        "  Uses selected embedding function (which is here our feature vector function)\n",
        "  and turns dataset and vocabulary into its embedding.  \n",
        "  \"\"\"\n",
        "  shape = [len(X_train), max(len(text) for text in X_train)] + [len(embedd_f(\"default\"))]\n",
        "\n",
        "  print(\"Padded shape of training set is {}\".format(shape))\n",
        "  print(\"Running embedding function over the dataset ...\")\n",
        "\n",
        "  train_data = tempmap(shape=tuple(shape), dtype=np.float32) #np.zeros(shape)\n",
        "  for i, sentence in tqdm(enumerate(X_train), total=len(X_train)):\n",
        "      for j, word in enumerate(sentence):\n",
        "          train_data[i, j, :] = embedd_f(word)\n",
        "  print(\"Dataset prepared with embeddings into shape {}\".\n",
        "        format(train_data.shape))\n",
        "  \n",
        "  print(\"Running embedding function over the vocabulary ...\")\n",
        "  vocab_embedds = [(embedd_f(word), word) for word in vocab]\n",
        "  print(\"Done ...\")\n",
        "  return train_data, vocab_embedds\n",
        "\n",
        "print(\"Embeddings: creating dataset of floats from dataset of tokenized texts:\")\n",
        "train_data, vocab_embedds = prepare_dataset_with_embeddings(vocab,\n",
        "                                                             features_from_text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 3/5000 [00:00<03:17, 25.24it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Embeddings: creating dataset of floats from dataset of tokenized texts:\n",
            "Padded shape of training set is [5000, 1807, 174]\n",
            "Running embedding function over the dataset ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 5000/5000 [03:15<00:00, 25.54it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Dataset prepared with embeddings into shape (5000, 1807, 174)\n",
            "Running embedding function over the vocabulary ...\n",
            "Done ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYhtQrM50f_P",
        "colab_type": "text"
      },
      "source": [
        "## Autoencoders on embeddings/feature vectors:\n",
        "We will use the most simple autoencoder architecture, that just flattens the representation, runs it through a bottleneck with a dropout, then decodes and inflates again.  \n",
        "![architecture](https://drive.google.com/uc?export=view&id=1KMfr0cLY3cvp9KbqOjiQQZM9Ae7LK7MP)  \n",
        "(Image source: http://uksim.info/isms2016/CD/data/0665a174.pdf)  \n",
        "  \n",
        "The dropout mechanism  \n",
        "![dropout](https://drive.google.com/uc?export=view&id=1nYxmBMIx3QPFqBw-Q1hJOr-Hvi7ASx7d)  \n",
        "\n",
        "(Dropout illustration from https://towardsdatascience.com/applied-deep-learning-part-4-convolutional-neural-networks-584bc134c1e2 )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7PEGOnXwIHl",
        "colab_type": "code",
        "outputId": "98cd9924-483d-44d9-b14b-c6b5a30fde9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3692
        }
      },
      "source": [
        "def basic_autoencoder_architecture(window_size, encoding_dim,\n",
        "                                   train_data_shape):\n",
        "  \"\"\"  \n",
        "  Copied more or less from the keras blog:\n",
        "  https://blog.keras.io/building-autoencoders-in-keras.html\n",
        "  \n",
        "  encoding_dim is the size of our encoded representations\n",
        "  \"\"\"\n",
        "  inp_shape = window_size * train_data_shape[-1]  # flattened representation size\n",
        "\n",
        "  print(\"Architecture will compress data to {} fraction\"\n",
        "        .format(encoding_dim / inp_shape))\n",
        "\n",
        "  # this is our input placeholder\n",
        "  input_data = Input(shape=(window_size, train_data_shape[-1], ))\n",
        "  input_flat = Flatten()(input_data)\n",
        "  # \"encoded\" is the encoded representation of the input\n",
        "  encoded = Dense(encoding_dim, activation='tanh')(Dropout(0.15)(input_flat))\n",
        "  \n",
        "  # defined order of layers to apply when building atuencoder.\n",
        "  # If we instantiate the layers now and then only apply them functionally,\n",
        "  # they will share their (trained) weights\n",
        "  decoder_layers = [Dense(inp_shape, activation='tanh'),\n",
        "                    Reshape((window_size, train_data_shape[-1]))]\n",
        "  def apply_decoder_layers(inner_input):\n",
        "    out = inner_input\n",
        "    for layer in decoder_layers:\n",
        "      out = layer(out)\n",
        "    return out\n",
        "\n",
        "  # this model maps an input to its reconstruction\n",
        "  autoencoder = Model(input_data, apply_decoder_layers(encoded))\n",
        "\n",
        "  # this model maps an input to its encoded representation\n",
        "  encoder = Model(input_data, encoded)\n",
        "\n",
        "  # create a placeholder for an encoded input\n",
        "  encoded_input = Input(shape=(encoding_dim,))\n",
        "\n",
        "  # create the decoder model\n",
        "  decoder = Model(encoded_input, apply_decoder_layers(encoded_input))\n",
        "\n",
        "  autoencoder.compile(optimizer='adam', loss='mse')\n",
        "  return autoencoder, encoder, decoder\n",
        "\n",
        "\n",
        "def train_and_predict(architecture_f,\n",
        "                      train_data,\n",
        "                      window_size,\n",
        "                      valid_split_size=100, \n",
        "                      epochs=100, batch_size=100, **kwargs): \n",
        "    \"\"\"\n",
        "    The definition of the training process, which will create the autoencoder and\n",
        "    then run training.\n",
        "    Also processes training set into its inner representation in the autoencoder.\n",
        "    Outputs not only the autoencoder, but also the encoder and decoder.\n",
        "    \"\"\"\n",
        "    print(kwargs)\n",
        "    autoencoder, encoder, decoder = architecture_f(window_size=window_size, **kwargs)\n",
        "    \n",
        "    x_train = train_data[:-valid_split_size, :window_size, :].astype('float32')\n",
        "    x_test  = train_data[-valid_split_size:, :window_size, :].astype('float32')\n",
        "    #x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "    #x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
        "    print(x_train.shape)\n",
        "    print(x_test.shape)\n",
        "\n",
        "    autoencoder.fit(x_train, x_train,\n",
        "                    epochs=epochs,\n",
        "                    batch_size=batch_size,\n",
        "                    verbose=1,\n",
        "                    shuffle=True,\n",
        "                    validation_data=(x_test, x_test))\n",
        "\n",
        "    x_train_pred = encoder.predict(x_train)\n",
        "    x_test_pred = encoder.predict(x_test)\n",
        "    print(\"Predicted data on training and test\")\n",
        "    return x_train_pred, x_test_pred, autoencoder, encoder, decoder\n",
        "\n",
        "\n",
        "x_train_pred, x_test_pred, autoencoder, encoder, decoder = \\\n",
        "    train_and_predict(basic_autoencoder_architecture,\n",
        "                      train_data=train_data,\n",
        "                      window_size=20,\n",
        "                      encoding_dim=800,\n",
        "                      train_data_shape=train_data.shape,\n",
        "                     )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'encoding_dim': 800, 'train_data_shape': (5000, 1807, 174)}\n",
            "Architecture will compress data to 0.22988505747126436 fraction\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py:423: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "(4900, 20, 174)\n",
            "(100, 20, 174)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 4900 samples, validate on 100 samples\n",
            "Epoch 1/100\n",
            "4900/4900 [==============================] - 4s 724us/step - loss: 6.8563e-04 - val_loss: 4.1126e-04\n",
            "Epoch 2/100\n",
            "4900/4900 [==============================] - 1s 124us/step - loss: 3.5032e-04 - val_loss: 2.5312e-04\n",
            "Epoch 3/100\n",
            "4900/4900 [==============================] - 1s 124us/step - loss: 2.3089e-04 - val_loss: 1.7599e-04\n",
            "Epoch 4/100\n",
            "4900/4900 [==============================] - 1s 124us/step - loss: 1.9019e-04 - val_loss: 1.5395e-04\n",
            "Epoch 5/100\n",
            "4900/4900 [==============================] - 1s 129us/step - loss: 1.6906e-04 - val_loss: 1.3659e-04\n",
            "Epoch 6/100\n",
            "4900/4900 [==============================] - 1s 123us/step - loss: 1.5285e-04 - val_loss: 1.2325e-04\n",
            "Epoch 7/100\n",
            "4900/4900 [==============================] - 1s 125us/step - loss: 1.4123e-04 - val_loss: 1.1287e-04\n",
            "Epoch 8/100\n",
            "4900/4900 [==============================] - 1s 122us/step - loss: 1.3059e-04 - val_loss: 1.0527e-04\n",
            "Epoch 9/100\n",
            "4900/4900 [==============================] - 1s 122us/step - loss: 1.2394e-04 - val_loss: 9.8854e-05\n",
            "Epoch 10/100\n",
            "4900/4900 [==============================] - 1s 125us/step - loss: 1.1770e-04 - val_loss: 9.3849e-05\n",
            "Epoch 11/100\n",
            "4900/4900 [==============================] - 1s 126us/step - loss: 1.1245e-04 - val_loss: 8.9158e-05\n",
            "Epoch 12/100\n",
            "4900/4900 [==============================] - 1s 125us/step - loss: 1.0626e-04 - val_loss: 8.5197e-05\n",
            "Epoch 13/100\n",
            "4900/4900 [==============================] - 1s 124us/step - loss: 1.0235e-04 - val_loss: 8.1876e-05\n",
            "Epoch 14/100\n",
            "4900/4900 [==============================] - 1s 124us/step - loss: 9.7774e-05 - val_loss: 7.8115e-05\n",
            "Epoch 15/100\n",
            "4900/4900 [==============================] - 1s 124us/step - loss: 9.3941e-05 - val_loss: 7.4745e-05\n",
            "Epoch 16/100\n",
            "4900/4900 [==============================] - 1s 127us/step - loss: 9.1007e-05 - val_loss: 7.1992e-05\n",
            "Epoch 17/100\n",
            "4900/4900 [==============================] - 1s 127us/step - loss: 8.7409e-05 - val_loss: 6.9155e-05\n",
            "Epoch 18/100\n",
            "4900/4900 [==============================] - 1s 124us/step - loss: 8.4353e-05 - val_loss: 6.6616e-05\n",
            "Epoch 19/100\n",
            "4900/4900 [==============================] - 1s 124us/step - loss: 8.1891e-05 - val_loss: 6.4117e-05\n",
            "Epoch 20/100\n",
            "4900/4900 [==============================] - 1s 126us/step - loss: 7.9335e-05 - val_loss: 6.2014e-05\n",
            "Epoch 21/100\n",
            "4900/4900 [==============================] - 1s 126us/step - loss: 7.6595e-05 - val_loss: 6.0034e-05\n",
            "Epoch 22/100\n",
            "4900/4900 [==============================] - 1s 126us/step - loss: 7.5263e-05 - val_loss: 5.7972e-05\n",
            "Epoch 23/100\n",
            "4900/4900 [==============================] - 1s 126us/step - loss: 7.3236e-05 - val_loss: 5.6571e-05\n",
            "Epoch 24/100\n",
            "4900/4900 [==============================] - 1s 125us/step - loss: 7.1257e-05 - val_loss: 5.4306e-05\n",
            "Epoch 25/100\n",
            "4900/4900 [==============================] - 1s 128us/step - loss: 6.9413e-05 - val_loss: 5.3573e-05\n",
            "Epoch 26/100\n",
            "4900/4900 [==============================] - 1s 126us/step - loss: 6.8434e-05 - val_loss: 5.1328e-05\n",
            "Epoch 27/100\n",
            "4900/4900 [==============================] - 1s 126us/step - loss: 6.6724e-05 - val_loss: 5.0723e-05\n",
            "Epoch 28/100\n",
            "4900/4900 [==============================] - 1s 124us/step - loss: 6.5219e-05 - val_loss: 4.9493e-05\n",
            "Epoch 29/100\n",
            "4900/4900 [==============================] - 1s 125us/step - loss: 6.4919e-05 - val_loss: 4.8922e-05\n",
            "Epoch 30/100\n",
            "4900/4900 [==============================] - 1s 125us/step - loss: 6.3556e-05 - val_loss: 4.6864e-05\n",
            "Epoch 31/100\n",
            "4900/4900 [==============================] - 1s 125us/step - loss: 6.1949e-05 - val_loss: 4.6253e-05\n",
            "Epoch 32/100\n",
            "4900/4900 [==============================] - 1s 127us/step - loss: 6.1513e-05 - val_loss: 4.5653e-05\n",
            "Epoch 33/100\n",
            "4900/4900 [==============================] - 1s 124us/step - loss: 6.0979e-05 - val_loss: 4.4678e-05\n",
            "Epoch 34/100\n",
            "4900/4900 [==============================] - 1s 129us/step - loss: 5.9952e-05 - val_loss: 4.3149e-05\n",
            "Epoch 35/100\n",
            "4900/4900 [==============================] - 1s 123us/step - loss: 5.8719e-05 - val_loss: 4.2394e-05\n",
            "Epoch 36/100\n",
            "4900/4900 [==============================] - 1s 123us/step - loss: 5.8095e-05 - val_loss: 4.1683e-05\n",
            "Epoch 37/100\n",
            "4900/4900 [==============================] - 1s 124us/step - loss: 5.7710e-05 - val_loss: 4.0860e-05\n",
            "Epoch 38/100\n",
            "4900/4900 [==============================] - 1s 123us/step - loss: 5.7043e-05 - val_loss: 4.0600e-05\n",
            "Epoch 39/100\n",
            "4900/4900 [==============================] - 1s 126us/step - loss: 5.6620e-05 - val_loss: 4.0175e-05\n",
            "Epoch 40/100\n",
            "4900/4900 [==============================] - 1s 123us/step - loss: 5.6228e-05 - val_loss: 3.9404e-05\n",
            "Epoch 41/100\n",
            "4900/4900 [==============================] - 1s 125us/step - loss: 5.5293e-05 - val_loss: 3.8976e-05\n",
            "Epoch 42/100\n",
            "4900/4900 [==============================] - 1s 125us/step - loss: 5.4466e-05 - val_loss: 3.9115e-05\n",
            "Epoch 43/100\n",
            "4900/4900 [==============================] - 1s 123us/step - loss: 5.4260e-05 - val_loss: 3.9250e-05\n",
            "Epoch 44/100\n",
            "4900/4900 [==============================] - 1s 125us/step - loss: 5.4338e-05 - val_loss: 3.7641e-05\n",
            "Epoch 45/100\n",
            "4900/4900 [==============================] - 1s 125us/step - loss: 5.3675e-05 - val_loss: 3.7158e-05\n",
            "Epoch 46/100\n",
            "4900/4900 [==============================] - 1s 125us/step - loss: 5.3371e-05 - val_loss: 3.6418e-05\n",
            "Epoch 47/100\n",
            "4900/4900 [==============================] - 1s 123us/step - loss: 5.2801e-05 - val_loss: 3.6568e-05\n",
            "Epoch 48/100\n",
            "4900/4900 [==============================] - 1s 123us/step - loss: 5.2685e-05 - val_loss: 3.5152e-05\n",
            "Epoch 49/100\n",
            "4900/4900 [==============================] - 1s 125us/step - loss: 5.1739e-05 - val_loss: 3.5174e-05\n",
            "Epoch 50/100\n",
            "4900/4900 [==============================] - 1s 124us/step - loss: 5.1320e-05 - val_loss: 3.4468e-05\n",
            "Epoch 51/100\n",
            "4900/4900 [==============================] - 1s 123us/step - loss: 5.1311e-05 - val_loss: 3.4264e-05\n",
            "Epoch 52/100\n",
            "4900/4900 [==============================] - 1s 123us/step - loss: 5.1410e-05 - val_loss: 3.3528e-05\n",
            "Epoch 53/100\n",
            "4900/4900 [==============================] - 1s 123us/step - loss: 5.0944e-05 - val_loss: 3.3308e-05\n",
            "Epoch 54/100\n",
            "4900/4900 [==============================] - 1s 124us/step - loss: 5.1037e-05 - val_loss: 3.3807e-05\n",
            "Epoch 55/100\n",
            "4900/4900 [==============================] - 1s 123us/step - loss: 5.0959e-05 - val_loss: 3.2950e-05\n",
            "Epoch 56/100\n",
            "4900/4900 [==============================] - 1s 126us/step - loss: 5.0334e-05 - val_loss: 3.2554e-05\n",
            "Epoch 57/100\n",
            "4900/4900 [==============================] - 1s 124us/step - loss: 4.9825e-05 - val_loss: 3.2258e-05\n",
            "Epoch 58/100\n",
            "4900/4900 [==============================] - 1s 124us/step - loss: 4.9254e-05 - val_loss: 3.1612e-05\n",
            "Epoch 59/100\n",
            "4900/4900 [==============================] - 1s 126us/step - loss: 4.8961e-05 - val_loss: 3.1715e-05\n",
            "Epoch 60/100\n",
            "4900/4900 [==============================] - 1s 125us/step - loss: 4.8747e-05 - val_loss: 3.1480e-05\n",
            "Epoch 61/100\n",
            "4900/4900 [==============================] - 1s 125us/step - loss: 4.9170e-05 - val_loss: 3.1649e-05\n",
            "Epoch 62/100\n",
            "4900/4900 [==============================] - 1s 127us/step - loss: 4.8267e-05 - val_loss: 3.0657e-05\n",
            "Epoch 63/100\n",
            "4900/4900 [==============================] - 1s 126us/step - loss: 4.8310e-05 - val_loss: 3.0419e-05\n",
            "Epoch 64/100\n",
            "4900/4900 [==============================] - 1s 125us/step - loss: 4.8492e-05 - val_loss: 3.2285e-05\n",
            "Epoch 65/100\n",
            "4900/4900 [==============================] - 1s 126us/step - loss: 4.7687e-05 - val_loss: 2.9853e-05\n",
            "Epoch 66/100\n",
            "4900/4900 [==============================] - 1s 125us/step - loss: 4.7920e-05 - val_loss: 3.0059e-05\n",
            "Epoch 67/100\n",
            "4900/4900 [==============================] - 1s 124us/step - loss: 4.7619e-05 - val_loss: 2.9793e-05\n",
            "Epoch 68/100\n",
            "4900/4900 [==============================] - 1s 124us/step - loss: 4.7235e-05 - val_loss: 2.9799e-05\n",
            "Epoch 69/100\n",
            "4900/4900 [==============================] - 1s 126us/step - loss: 4.7648e-05 - val_loss: 2.9960e-05\n",
            "Epoch 70/100\n",
            "4900/4900 [==============================] - 1s 127us/step - loss: 4.7608e-05 - val_loss: 2.9785e-05\n",
            "Epoch 71/100\n",
            "4900/4900 [==============================] - 1s 126us/step - loss: 4.7419e-05 - val_loss: 2.9259e-05\n",
            "Epoch 72/100\n",
            "4900/4900 [==============================] - 1s 124us/step - loss: 4.6596e-05 - val_loss: 2.8991e-05\n",
            "Epoch 73/100\n",
            "4900/4900 [==============================] - 1s 123us/step - loss: 4.6796e-05 - val_loss: 2.9051e-05\n",
            "Epoch 74/100\n",
            "4900/4900 [==============================] - 1s 126us/step - loss: 4.6146e-05 - val_loss: 2.8771e-05\n",
            "Epoch 75/100\n",
            "4900/4900 [==============================] - 1s 125us/step - loss: 4.6650e-05 - val_loss: 2.8847e-05\n",
            "Epoch 76/100\n",
            "4900/4900 [==============================] - 1s 127us/step - loss: 4.6014e-05 - val_loss: 2.8855e-05\n",
            "Epoch 77/100\n",
            "4900/4900 [==============================] - 1s 125us/step - loss: 4.5912e-05 - val_loss: 2.7886e-05\n",
            "Epoch 78/100\n",
            "4900/4900 [==============================] - 1s 123us/step - loss: 4.6025e-05 - val_loss: 2.7837e-05\n",
            "Epoch 79/100\n",
            "4900/4900 [==============================] - 1s 126us/step - loss: 4.5310e-05 - val_loss: 2.7852e-05\n",
            "Epoch 80/100\n",
            "4900/4900 [==============================] - 1s 124us/step - loss: 4.5610e-05 - val_loss: 2.7005e-05\n",
            "Epoch 81/100\n",
            "4900/4900 [==============================] - 1s 126us/step - loss: 4.5623e-05 - val_loss: 2.7713e-05\n",
            "Epoch 82/100\n",
            "4900/4900 [==============================] - 1s 126us/step - loss: 4.5369e-05 - val_loss: 2.7745e-05\n",
            "Epoch 83/100\n",
            "4900/4900 [==============================] - 1s 124us/step - loss: 4.4955e-05 - val_loss: 2.6895e-05\n",
            "Epoch 84/100\n",
            "4900/4900 [==============================] - 1s 125us/step - loss: 4.5229e-05 - val_loss: 2.6946e-05\n",
            "Epoch 85/100\n",
            "4900/4900 [==============================] - 1s 126us/step - loss: 4.5243e-05 - val_loss: 2.6592e-05\n",
            "Epoch 86/100\n",
            "4900/4900 [==============================] - 1s 126us/step - loss: 4.4272e-05 - val_loss: 2.6258e-05\n",
            "Epoch 87/100\n",
            "4900/4900 [==============================] - 1s 125us/step - loss: 4.4702e-05 - val_loss: 2.6372e-05\n",
            "Epoch 88/100\n",
            "4900/4900 [==============================] - 1s 126us/step - loss: 4.4745e-05 - val_loss: 2.7755e-05\n",
            "Epoch 89/100\n",
            "4900/4900 [==============================] - 1s 127us/step - loss: 4.4821e-05 - val_loss: 2.6327e-05\n",
            "Epoch 90/100\n",
            "4900/4900 [==============================] - 1s 127us/step - loss: 4.4182e-05 - val_loss: 2.6259e-05\n",
            "Epoch 91/100\n",
            "4900/4900 [==============================] - 1s 126us/step - loss: 4.4969e-05 - val_loss: 2.6623e-05\n",
            "Epoch 92/100\n",
            "4900/4900 [==============================] - 1s 126us/step - loss: 4.4144e-05 - val_loss: 2.6541e-05\n",
            "Epoch 93/100\n",
            "4900/4900 [==============================] - 1s 126us/step - loss: 4.4255e-05 - val_loss: 2.5779e-05\n",
            "Epoch 94/100\n",
            "4900/4900 [==============================] - 1s 127us/step - loss: 4.4236e-05 - val_loss: 2.5584e-05\n",
            "Epoch 95/100\n",
            "4900/4900 [==============================] - 1s 125us/step - loss: 4.3868e-05 - val_loss: 2.6515e-05\n",
            "Epoch 96/100\n",
            "4900/4900 [==============================] - 1s 126us/step - loss: 4.4000e-05 - val_loss: 2.5746e-05\n",
            "Epoch 97/100\n",
            "4900/4900 [==============================] - 1s 126us/step - loss: 4.3497e-05 - val_loss: 2.6186e-05\n",
            "Epoch 98/100\n",
            "4900/4900 [==============================] - 1s 126us/step - loss: 4.4081e-05 - val_loss: 2.5133e-05\n",
            "Epoch 99/100\n",
            "4900/4900 [==============================] - 1s 126us/step - loss: 4.3592e-05 - val_loss: 2.5336e-05\n",
            "Epoch 100/100\n",
            "4900/4900 [==============================] - 1s 125us/step - loss: 4.3017e-05 - val_loss: 2.5567e-05\n",
            "Predicted data on training and test\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4bduPcs0ttm",
        "colab_type": "text"
      },
      "source": [
        "# Evaluating and usages basics:  \n",
        "  \n",
        "We have trained an autoencoder. Now lets go through some basic usecases and deduct what is the autoencoder doing! In each case we will also pint out what shoukd be the best non-toy model fo that task. \n",
        "(Can we guess now, what is the toy autoencoder doing?)  \n",
        "  \n",
        "Hints we could know from the architecture are:\n",
        "- Not every autoencoder is suitable for every task, so some of usecases can be misleading in our detective work\n",
        "- The autoencoder is the most basic one, so it would not do fancy stuff\n",
        "  - Analogy in the world of CNNs for images is, that only the deep layers do recognize objects or faces.\n",
        "- The given features are balanced to every character, they should not favor anything"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DmUI-HX804K",
        "colab_type": "text"
      },
      "source": [
        "### Looking at how the autoencoder handles a sentence from the training set\n",
        "Real usecases can be data compression, pretraining layers for bigger model, machine translation, or just a test for ruling out bad architectures.  \n",
        "Also there is a class of denoising autoencoders which should not only reconstruct a sentence, but also to repair a modified sentence (reconstruct randomly altered input)\n",
        "*Best used: *"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0J9PrEbV809W",
        "colab_type": "code",
        "outputId": "07989bfe-e01e-4b50-a689-99e5348f982b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "def simply_word_in_embedd_vocab(item, vocab_embedds):\n",
        "  \"\"\"\n",
        "  Lets use the vocabulary search to get just the word from the ()predicted) features.\n",
        "  \"\"\"\n",
        "  search_result = vocab_finder(item, vocab_embedds, key_f=lambda item: item[0],\n",
        "                               apply_on_item_too=False)\n",
        "  # search_result = ((ith position, the vocabulary item), score)\n",
        "  # the vocabulary item is (embedd_f(word), word)\n",
        "  \n",
        "  return search_result[0][1][1]\n",
        " \n",
        "\n",
        "def compare_reconstructed(batch,\n",
        "                          autoencoder=autoencoder,\n",
        "                          emb2text=lambda emb: simply_word_in_embedd_vocab(emb, vocab_embedds),\n",
        "                          verbose=True\n",
        "                         ):\n",
        "    \"\"\"\n",
        "    This function would compare the original sentence to:\n",
        "    - a sentence reconstructed without the autoencoder, just from word features and vocabulary\n",
        "    - a sentence reconstructed using the autoencoder\n",
        "\n",
        "    Also we can measure the MSE of the original and the reconstructed\n",
        "    (without using the vocabulary to separate the effects).\n",
        "    \"\"\"\n",
        "    prediction = autoencoder.predict_on_batch(batch)\n",
        "    \n",
        "    ret = []\n",
        "    \n",
        "    for pred_item, batch_item in zip(prediction, batch):\n",
        "        word_by_word  = batch_item #np.reshape(batch_item, (-1, train_data.shape[-1]))\n",
        "        orig = u\" \".join([emb2text(word) for word in word_by_word])\n",
        "               \n",
        "        pred_by_word  = pred_item #np.reshape(pred_item, (-1, train_data.shape[-1]))\n",
        "        pred = u\" \".join([emb2text(word) for word in pred_by_word])\n",
        "    \n",
        "        mse = np.mean(np.square(word_by_word - pred_by_word))\n",
        "        if verbose:\n",
        "          print(u\"\\n \\n --Original sentence reconstructed just from vocabulary: \\n\"\n",
        "          \"{}\\n\"\n",
        "          \"--Predicted sentence reconstructed by autoencoder AND vocabulary: \\n\"\n",
        "          \"{}\\n\"\n",
        "          \"--mse: {}; ({})\\n\".format(orig, pred, mse,\n",
        "                                  u\"(different)\" if orig != pred else u\"same\"))\n",
        "        ret.append((orig, pred, mse))\n",
        "    return ret\n",
        "\n",
        "\n",
        "print(\"2 things from training set:\")\n",
        "compare_reconstructed(train_data[0:2, :20])\n",
        "print(\" ... seems pretty OK\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2 things from training set:\n",
            "\n",
            " \n",
            " --Original sentence reconstructed just from vocabulary: \n",
            "the basic plot in this movie sin ! t bad ! a lady makes it big and comes back to\n",
            "--Predicted sentence reconstructed by autoencoder AND vocabulary: \n",
            "the basic plot in this movie sin ! t bad ! a lady makes it big and comes back to\n",
            "--mse: 1.0575998203421477e-05; (same)\n",
            "\n",
            "\n",
            " \n",
            " --Original sentence reconstructed just from vocabulary: \n",
            "i found this film embarrassing to watch ! i felt like it was shoving the storyline down my throat as\n",
            "--Predicted sentence reconstructed by autoencoder AND vocabulary: \n",
            "i found this film researching to watch ! i felt like it was shoving the storyline down my throat as\n",
            "--mse: 1.6458803656860255e-05; ((different))\n",
            "\n",
            " ... seems pretty OK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfAnw2Qz1oEV",
        "colab_type": "text"
      },
      "source": [
        "### Generating random sentence with the model:\n",
        "Given random inner representation, it should produce a random sentence.  \n",
        "Usefull also for randomly altering a sentence.  \n",
        "\n",
        "*Best used: for non-toy example, more suitable autoencoder architecture should be the VAE (Variational autoencoder), possibly with embeddings.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pA0Qu2ZLUM3",
        "colab_type": "code",
        "outputId": "1803b933-0aed-4344-96b4-f4a0ebf319c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "def generate_from_inner(batch,\n",
        "                          decoder=decoder,\n",
        "                          emb2text=lambda emb: simply_word_in_embedd_vocab(emb, vocab_embedds),\n",
        "                          verbose=True\n",
        "                         ):\n",
        "    \"\"\"\n",
        "    Given a batch, produces a text, regarding the batch as batch of inner representation features.\n",
        "    \"\"\"\n",
        "    prediction = decoder.predict_on_batch(batch)\n",
        "    ret = []\n",
        "    for pred_item in prediction:\n",
        "        pred_by_word = pred_item # np.reshape(batch_item, (-1, train_data.shape[-1]))\n",
        "        pred = u\" \".join([emb2text(word) for word in pred_by_word])\n",
        "               \n",
        "        ret.append(pred)\n",
        "    return ret\n",
        "\n",
        "print(\"Inspecting random inner representation as sentence:\") \n",
        "print(\"\")\n",
        "zero_input_inner = np.random.rand(*tuple([dim.value if dim.value is not None else 1 for dim in decoder.inputs[0].shape]))\n",
        "print(generate_from_inner(zero_input_inner))\n",
        "print(\"\")\n",
        "print(\"... seems that the autoencoder did not grasp sentence meanings and does not use most common words\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Inspecting random inner representation as sentence:\n",
            "\n",
            "['chick-flick civilized 81 underdeveloped 61 n greengrass full vs n aftermath besides 53 flee 29 10 13 p masochistic scumbags']\n",
            "\n",
            "... seems that the autoencoder did not grasp sentence meanings and does not use most common words\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5fd_V_C9icU",
        "colab_type": "text"
      },
      "source": [
        "### Inspecting a custom sentence:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lANSADhf9OgF",
        "colab_type": "text"
      },
      "source": [
        "Real world usage would include finding a close sentence in inner representation.  \n",
        "\n",
        "*Best used: In fact it does not need an autoencoder, inner representation can be also taken as the last layer in any trained model - then the closest sentence would be a sentence with closer target values.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-fPXXYZ1mfY",
        "colab_type": "code",
        "outputId": "7789b766-cafe-404a-bfff-26b6ad759c79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "def sentence_into_batch(sentence,\n",
        "                        window_size=20,\n",
        "                        train_data_shape=train_data.shape,\n",
        "                        tokenize_f=text_tokens,\n",
        "                        embedd_f=features_from_text):\n",
        "  \"\"\"\n",
        "  Given a custom sentence, proceses it into a batch to be fed into the model.\n",
        "  \"\"\"\n",
        "  if tokenize_f is None:\n",
        "    tokenize_f = lambda x: x\n",
        "  \n",
        "  custom_b = np.zeros((1, window_size, train_data_shape[-1]))\n",
        "  for i, word in enumerate(tokenize_f(sentence)):\n",
        "      if i >= window_size:\n",
        "          break\n",
        "      custom_b[0, i, :] = embedd_f(word)\n",
        "  return custom_b \n",
        "\n",
        "\n",
        "def inspect_custom_sentence(custom_sentence,\n",
        "                            autoencoder=autoencoder,                            \n",
        "                            encoder=encoder,                            \n",
        "                            embedd_f=features_from_text,\n",
        "                            window_size=20,\n",
        "                            tokenize_f=text_tokens,\n",
        "                            train_data_shape=train_data.shape,\n",
        "                            find_closest_representatios=x_train_pred,\n",
        "                            original_sentences=X_train_orig):\n",
        "    \"\"\"\n",
        "    Given a custom sentence, inspects using compare_reconstructed function and\n",
        "    also tries to find the closest sentence in the training set.\n",
        "    \"\"\"\n",
        "  \n",
        "    custom_b = sentence_into_batch(custom_sentence,\n",
        "                                    window_size,\n",
        "                                    train_data_shape,\n",
        "                                    tokenize_f,\n",
        "                                    embedd_f)\n",
        "\n",
        "    print(\"Reconstructed custom sentence (only using vocabulary): \")\n",
        "    compare_reconstructed(custom_b, autoencoder)  # todo some our words might not be in vocabulary\n",
        "\n",
        "    print(\"Most similar sentence in trained encoder's representation: \")\n",
        "    similar_sentence = vocab_finder(encoder.predict_on_batch(custom_b)[0],\n",
        "                                    find_closest_representatios,\n",
        "                                    None)[0][0]\n",
        "    print(u\" \".join(original_sentences[similar_sentence][0:window_size]))\n",
        "    \n",
        "\n",
        "print(\"Inspecting custom sentence\")  \n",
        "print(\"\")\n",
        "inspect_custom_sentence(u\"This SF film really captured me, \"\n",
        "                        \"I have enjoyed the starships flying \"\n",
        "                        \"and people jumping all around space\")\n",
        "print(\"\")\n",
        "print(\" ... ok, works on non training dataset sentence, but the inner representation does not seem to convey any close meaning\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Inspecting custom sentence\n",
            "\n",
            "Reconstructed custom sentence (only using vocabulary): \n",
            "\n",
            " \n",
            " --Original sentence reconstructed just from vocabulary: \n",
            "this s film really captured me ! i have enjoyed the starship flying and people jumping all around space !\n",
            "--Predicted sentence reconstructed by autoencoder AND vocabulary: \n",
            "this sf film really capture me ! i have enjoyed the starship flying and people jumping all around space a\n",
            "--mse: 2.6760561871722076e-05; ((different))\n",
            "\n",
            "Most similar sentence in trained encoder's representation: \n",
            "This had a great cast with big - name stars like Tyrone Power , Henry Fonda , Randolph Scott ,\n",
            "\n",
            " ... ok, works on non training dataset sentence, but the inner representation does not seem to convey any close meaning\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leQDUy7s1tgy",
        "colab_type": "text"
      },
      "source": [
        "### Anomaly detection \n",
        "Lets reconstruct each sentence using the autoencoder and select the most different reconstruction as anomaly.  \n",
        "I have employed some sentences from the training data and some based on my own hypothesis to verify it.\n",
        "![anomaly detection](https://www.spiedigitallibrary.org/ContentImages/Proceedings/10630/1063006/FigureImages/00004_PSISDG10630_1063006_page_4_1.jpg)  \n",
        "(Image source: https://www.spiedigitallibrary.org/conference-proceedings-of-spie/10630/1063006/Deep-learning-based-classification-and-anomaly-detection-of-side-channel/10.1117/12.2311329.short)\n",
        "  \n",
        "Autoencoders are sometimes used to fulfill this role of anomaly detection in financial markets; for that purpose they are retrained often (each 5 minutes).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KZBL7Dv1jji",
        "colab_type": "code",
        "outputId": "000edb7d-6a83-4586-f00f-2aa51c065060",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "print(\"Inspecting anomalies: (bigger number means bigger anomaly) \\n \"\n",
        "      \"Last 5 sentences are form the training set, first 3 are custom \\n\") \n",
        "\n",
        "custom_anomaly_test = [\n",
        "u\"A wise Klingon once said: hjtcuyf fkudkuyfliug htdjiugh yffkjgkj wsdihga apfgihag agafg iha ah jasth qt FGRIH G.\",\n",
        "u\"2018 was my 2. most enjoyable year with films. All 10 films I saw did really count.\",\n",
        "u\"Aaaaargh! Autoencoders should not be screaaaaming! Aaaaand I think It does it because I waaaant to confuse it!\",\n",
        "u\"the movie seems disjointed and overall , poorly written . the screenplay moves along as if 10 different people wrote it , and none of them were communicating with each other.\",\n",
        "u\"dennis hopper is without a doubt one of the finest underrated american actors of our time , and it was interesting to see how he would play out his role as a cop on the case of a child serial killer\",\n",
        "u\"this movie should not be viewed unless you are trying to kill yourself . i think this movie could actually cause severe brain damage . the main characters are the whiny non - hero kevin , amy.\",\n",
        "u\"this film reminds me of how college students used to protest against the vietnam war . as if , upon hearing some kids were doing without cheeseburgers in cow dung collehe , the president was.\",\n",
        "u\"to compare this squalor with an old , low budget flick would be an insult to the old , low budget flick . the animal scenes have no meaning nor do they represent this man and his crimes.\",\n",
        "]\n",
        "\n",
        "anomaly_results = [compare_reconstructed(sentence_into_batch(anomaly),\n",
        "                                        verbose=False)[0] \n",
        "                   for anomaly in custom_anomaly_test]\n",
        "\n",
        "for i, ano_res in enumerate(anomaly_results):\n",
        "  print((\"%.7f\" % ano_res[-1]) + \": \" + custom_anomaly_test[i])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Inspecting anomalies: (bigger number means bigger anomaly) \n",
            " Last 5 sentences are form the training set, first 3 are custom \n",
            "\n",
            "0.0000636: A wise Klingon once said: hjtcuyf fkudkuyfliug htdjiugh yffkjgkj wsdihga apfgihag agafg iha ah jasth qt FGRIH G.\n",
            "0.0000683: 2018 was my 2. most enjoyable year with films. All 10 films I saw did really count.\n",
            "0.0000394: Aaaaargh! Autoencoders should not be screaaaaming! Aaaaand I think It does it because I waaaant to confuse it!\n",
            "0.0000324: the movie seems disjointed and overall , poorly written . the screenplay moves along as if 10 different people wrote it , and none of them were communicating with each other.\n",
            "0.0000194: dennis hopper is without a doubt one of the finest underrated american actors of our time , and it was interesting to see how he would play out his role as a cop on the case of a child serial killer\n",
            "0.0000157: this movie should not be viewed unless you are trying to kill yourself . i think this movie could actually cause severe brain damage . the main characters are the whiny non - hero kevin , amy.\n",
            "0.0000199: this film reminds me of how college students used to protest against the vietnam war . as if , upon hearing some kids were doing without cheeseburgers in cow dung collehe , the president was.\n",
            "0.0000169: to compare this squalor with an old , low budget flick would be an insult to the old , low budget flick . the animal scenes have no meaning nor do they represent this man and his crimes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mcr6KhwD1F2w",
        "colab_type": "text"
      },
      "source": [
        "### Evaluating with clustering:\n",
        "- See how a clustering algorithm is able to treat our data, is it able to find any clusters?\n",
        "- How do we evaluate clusters? Lets just look at some sentences from a noncommon cluster, if they have the same theme"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofH-Q2G6wN9V",
        "colab_type": "code",
        "outputId": "6738878e-2a2c-40bd-f674-6596b3f1de5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# https://scikit-learn.org/stable/modules/generated/sklearn.cluster.Birch.html\n",
        "def compute_clusters(features, threshold=0.9):\n",
        "    print('Computing clusters... from {} datapoints'.format(features.shape[0]))\n",
        "    # `n_clusters=None` means variable number of clusters\n",
        "    # we control clustering by the threshold\n",
        "    cluster_algo = Birch(n_clusters=None, threshold=threshold)\n",
        "    # predicted cluster labels (typically integers from 0)\n",
        "    clusters = cluster_algo.fit_predict(features)\n",
        "    cluster_count = len(set(clusters))\n",
        "    print('Cluster count:', cluster_count)\n",
        "    return clusters\n",
        "\n",
        "ret_clust = compute_clusters(x_train_pred)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Computing clusters... from 4900 datapoints\n",
            "Cluster count: 47\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLKlgdNdwSUn",
        "colab_type": "code",
        "outputId": "ba944d3b-f02d-4d31-a33f-91aca2249d5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        }
      },
      "source": [
        "def print_cluster_example(cluster_i=0, n_examples=10):\n",
        "  ids = [i for i, clust in enumerate(ret_clust) if clust == cluster_i]\n",
        "  ids = ids[:n_examples]\n",
        "  print(ids)\n",
        "  for oid in ids:\n",
        "      print(u\"\")\n",
        "      print(u\"id {}\".format(oid))\n",
        "      print(u\" \".join(X_train_orig[oid]))\n",
        "      \n",
        "def find_less_count_clusters():\n",
        "  from collections import Counter\n",
        "  rets = Counter(ret_clust)\n",
        "  for key in rets.keys():\n",
        "    if rets[key] <= 10 and rets[key] >= 3:\n",
        "      return key\n",
        "  \n",
        "print(\"Inspecting some small cluster:\")\n",
        "print(\"\")\n",
        "print_cluster_example(cluster_i=find_less_count_clusters(), n_examples=10)\n",
        "print(\"\")\n",
        "print(\"Ok notice the numbers and their positions in the sentence!\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Inspecting some small cluster:\n",
            "\n",
            "[131, 535, 805, 900, 1088, 3260, 3262, 4497]\n",
            "\n",
            "id 131\n",
            "The only previous Gordon film I had watched was the kiddie adventure THE MAGIC SWORD ( 1962 ), though I followed this soon after with EMPIRE OF THE ANTS ( 1977 ); he seems to be best remembered , however , for his sci - fi work of the 1950s . Anyway , I happened upon this one in a DVD rental shop : hadn ' t I noticed Orson Welles ' unmistakable figure on the sleeve , I probably wouldn ' t even have bothered with it – since I know the film under its original title , NECROMANCY ! I ' d seen a still from it on an old horror tome of my father ' s : the actor ' s presence in a film about diabolism seemed like a great idea which couldn ' t possibly miss , but the end result – particularly in this bastardized edition – is a disaster ! I honestly felt sorry for Welles who looks bored and , rather than in his deep and commanding voice , he mutters the inane demonic invocations almost in whispers !! The plot is , basically , yet another retread of ROSEMARY ' S BABY ( 1968 ): a couple is invited to a remote community under false pretenses and soon discover themselves to be surrounded by diabolists . The girl , played by Pamela Franklin , ostensibly has supernatural powers ( passed on from her mother , who appears intermittently throughout to warn her – though , as delivered in an intense manner through clenched teeth , the latter ' s speeches end up being largely incoherent and the fount of immense hilarity every time she appears !) and is expected to revive Welles ' deceased young son from the dead !! For what it ' s worth , Franklin – a genre regular , right down from her debut performance in THE INNOCENTS ( 1961 )– isn ' t bad in her role ( which requires some nudity and experiences several semi - eerie hallucinations during the course of the film ); hubby Michael Ontkean , however , isn ' t up to the challenge of his John Cassavetes - like character . Some of the other girls look good as well – notably Lee Purcell , whose belated decision to help Franklin in escaping from town eventually proves her undoing . Events come to a head in an incredibly muddled climax , which sees the Satanists ultimately turning on Franklin and have her take the revived boy ' s place in the coffin ( that ' s gratitude for you !). While the added scenes do stick out ( the hilarious opening ceremony and other would - be erotic embellishments ), the overall quality of the film would have still been poor without them ; then again , this particular version is further sunk by the tacked - on electronic score – which is wholly inappropriate , and cheesy in the extreme !\n",
            "\n",
            "id 535\n",
            "I have no idea what idiots gave this movie a Palm D ' Or at the 1999 Cannes Film Festival because it was atrocious ! I actually watched the entire thing simply because I couldn ' t believe that someone would make such a worthless film . There is nothing interesting about the plot , the characters are devoid of depth and there is no attempt at giving any sort of ambiance with music or sound effects . Also , if you do decide to waste 2 hours of your life by watching this film , be sure to bring something to throw up in because the cinematography is simply someone running around with a hand - held camcorder and half the time you can ' t even see the main subjects . This style has been used much more successfully in movies such as \" Blair Witch \" because it creates suspense . In Rosetta , there is no plot and no suspense to which that style would lend anything . I should have known better when it came on at 2 o ' clock in the morning that it was going to be horrible .\n",
            "\n",
            "id 805\n",
            "I had high hopes for it when I heard that it was being made back in 2001 because I read \" The Devil and Daniel Webster \" when I was a kid and I found it very interesting . They made some changes to the story that don ' t make much sense to me . Daniel Webster in the story was a famous lawyer from New Hampshire in the story . In the movie he is an editor . A lawyer makes more sense since he ends up representing Jabez Stone against the devil him / herself ( he was a man in the story , but was a woman in the movie ) in a trial where both of their souls are on the line . As an editor , it doesn ' t seem likely that Daniel Webster would have the skill to do this . The acting was decent by all except for Alec Baldwin and Dan Aykroyd . These are two actors that I like , they just did an awful job in this movie . It was as though they thought they were acting in a comedy , but the movie was more a serious one than a comedy . This might be partly due to the fact that the movie was filmed with a particular vision in mind , and was then re - edited by somebody else . Given this fact , it ' s surprising that it was at all coherent . I was surprised to see a fair amount of SNL cast members in the movie , which further leads me to believe it may have originally been filmed with the intention of it being more of a comedy . All in all I would have to say it wasn ' t completely awful , but it wasn ' t much good . If I could get the hour and a half back and do something else with it , I would . The ending was especially disappointing . As in the original story , Daniel Webster defeats the devil in the trial . Jabez then starts out again at the beginning of the movie ... literally , we are just brought back to the first scene with Jabez , and then the movie abruptly ends . It actually looked as though they just replayed Jabez ' first scene over and called it the end . There is no indication that Jabez has the benefit of any of the knowledge or experience he gained , so who is to say he didn ' t just repeat his mistakes over again , and perhaps over and over in an endless loop ? It was an extremely disappointing end and did not make a lot of sense . The decent cast , and the acting of everyone except for Baldwin and Aykroyd are the only things that keep this from being a complete and total crap sandwich .\n",
            "\n",
            "id 900\n",
            "I sincerely consider this movie as another poor effort of Dominican Movie Industry . The first 30 minutes of the movie are a little funny but then when they switch their role in the society ( men doing what women usually do and women doing what men usually do ) the movie falls . Becoming boring and not funny at all . They let many things without explanation and the end of the movie is predictable . I didn ' t like the way as a Roberto Angel played his character and his little either . I went to the movies theater hoping to see a good work but I went out really disappointed . I don ' t recommend this movie .\n",
            "\n",
            "id 1088\n",
            " Whether any indictment was intended must be taken into consideration . If in the year 2000 there were still rifts of feeling between Caucasian and Afro - Americans in Georgia , such as shown in this film , obviously there remains a somewhat backward mentality among a lot of people out there . It is rather hypocritical , to say the least , if everyone adores Halle Berry , Whoopie Goldberg , Beyoncé , Noemi Campbell , Denzel Washington , Will Smith , et . al ., whilst out in the backs there persist manifest racial divides . White grandmother suddenly gets black grand - daughter thrust upon her , only to meet up with black grandfather in a very white social backwater . The story is sweet , not lacking tragic overtones , and eminently predictable as in most of these kinds of TV films , though the final scene has you guessing ............ will he ? won ' t he .......? Gena Rowlands in her typical style offers a sincere rendering , and Louis Gossett is a good match for her ; the little Penny Bae fortunately does not steal the show . A ` nice ' way of relaxing after Sunday lunch without having to force your mind too much , though you might just find yourself having a little siesta in the middle of it .\n",
            "\n",
            "id 3260\n",
            "If I had known this movie was filmed in the exasperating and quease - inducing Dogme 95 style , I would never have rented it . Nevertheless , I took a dramamine for the seasickness and gave it a shot . I lasted a very , very , very long forty minutes before giving up . It ' s just boring , pretentious twaddle . The last French movie I saw was \" Romance \" and it too was pretty dismal , but at least the camera was steady and not breathing down the necks of the characters all the time . I am baffled at the continuing popularity of Dogme 95 overseas -- it ' ll catch on in America about the same time as the next big outbreak of leprosy .( It ' s called Dogme 95 because that ' s the average number of times the actors are poked in the eye by the camera .)\n",
            "\n",
            "id 3262\n",
            "Never cast models and Playboy bunnies in your films ! Bob Fosse ' s \" Star 80 \" about Dorothy Stratten , of whom Bogdanovich was obsessed enough to have married her SISTER after her murder at the hands of her low - life husband , is a zillion times more interesting than Dorothy herself on the silver screen . Patty Hansen is no actress either .. I expected to see some sort of lost masterpiece a la Orson Welles but instead got Audrey Hepburn cavorting in jeans and a god - awful \" poodlesque \" hair - do .... Very disappointing ....\" Paper Moon \" and \" The Last Picture Show \" I could watch again and again . This clunker I could barely sit through once . This movie was reputedly not released because of the brouhaha surrounding Ms . Stratten ' s tawdry death ; I think the real reason was because it was so bad !\n",
            "\n",
            "id 4497\n",
            "The only reason i am bothering to comment on this movie is to save you all 97 minutes of your life and maybe your money . I bought it ex - rental for £ 3 . 00 , it looked interesting , so i took a chance . Within minutes of turning it on i realised i ' d made a mistake . The entire cast should be stored away until winter and then thrown on the nearest log fire , where they could meet more of their kind . As for the Devin Hamilton ( Writer and Director ), he should just be shot , sadly this should have been done before he made this rubbish . Avoid this film , If you see it in the shops run away . 1 / 10\n",
            "\n",
            "Ok notice the numbers and their positions in the sentence!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZR25TkjWAWWq",
        "colab_type": "code",
        "outputId": "6a8e0e95-4a43-4d00-b0e5-9efb5dc8282f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "source": [
        "print(\"How are the clusters looking? Lets just inspect them with TSNE for visualization: \")\n",
        "Y = tsne(np.float64(x_train_pred[0:5000]))\n",
        "plt.scatter(Y[:, 0], Y[:, 1])\n",
        "plt.show()\n",
        "\"\"\"\n",
        "If we have used a variational autoencoder, it coud make sense to display just the inner representation:\n",
        "print(\"Here we will take the first two coordinates from the inner representation and display it\"\n",
        "      \"(useful when using variational autoencoder or autoencoder with just 2 units)\")\n",
        "plt.scatter(x_train_pred[:, 0], x_train_pred[:, 1])\n",
        "plt.show()\n",
        "\"\"\"\n",
        "print(\"\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "How are the clusters looking? Lets just inspect them with TSNE for visualization: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeQAAAFNCAYAAADRvRzfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQEAsqARUBVEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZ0b9z2GLUtJ",
        "colab_type": "code",
        "outputId": "ea671bf9-71b3-4715-e2a7-32d8ce735047",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "print(\"Idea: We could inspect the small clusters in the TSNE representation: \\n\")\n",
        "point_inspect = [30, -20]  # input your own point\n",
        "\n",
        "dists = [(i, (point_inspect[0]-item[0])*(point_inspect[0]-item[0]) +\n",
        "          (point_inspect[1]-item[1])*(point_inspect[1]-item[1])) \n",
        "         for i, item in enumerate(Y)]\n",
        "dists.sort(key=lambda item: item[1])\n",
        "[\" \".join(X_train_orig[item[0]]) for item in dists[0:5]]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Idea: We could inspect the small clusters in the TSNE representation: \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\" According to reviewers , the year is 1955 and the players are 20 year - old college kids about to enter grad school . Jolly joke ! 1955 ? The synthesizer keyboard was not invented yet , but there it is on the bandstand . The Ford Pony Car was not invented yet , but there it is playing oldies music . The synthesizer appeared to be a model from the mid 1970 ' s . The Pony Car at best is from the mid 1960 ' s . 20 year - old college kids ? Josh Brolin had seen 32 birthdays when this made - for - TV movie was produced . The plot is so predictable that viewers have plenty of spare time to think of all the errors appearing upon their TV ' s .\",\n",
              " 'I personally liked \" The Prophecy \" of 1995 a lot . Christopher Walken was , as always , great , and even though the film wasn \\' t flawless , it was a creepy and highly original Horror / Fantasy film that entertained immensely . This inferior 1998 sequel is still worth watching , but mainly due to Walken . Walken is one of the greatest actors around , in my opinion , and he is once again outstanding in the role of the fallen Archangel Gabriel , whom he plays for the second time here . Once again , the war between fallen and loyal Angels is brought to earth . Gabriel returns in order to prevent the birth of a child , namely the child of the angel Danyael ( Russel Wong ) and the human woman Valerie ( Jennifer Beals ). This child could once be the determining factor of the celestial war ... As I said above , Christopher Walken is once again excellent as Gabriel . Besides Gabriel , however ,\" The Prophecy II \" sadly also includes a bunch of terribly annoying characters . The character of Valerie was annoying enough , and Danayel annoyed me even more . The biggest pain in the ass , however was the character of Izzy ( played by Brittany Murphy ), a suicidal girl who wouldn \\' t shut up . Still , Walken \\' s performance isn \\' t the only redeeming quality of the film . The entire film is quite dreary , and well - shot in dark colors , which contributes a lot to the atmosphere . Gabriel \\' s resurrection scene in the beginning is furthermore quite impressive , and one of the coolest moments in any of the \" Prophecy \" films .\" The Prophecy II \" is nevertheless the weakest of the three \" Prophecy \" films with Walken . Definitely a Christopher Walken one - man - show , entertaining , but nothing beyond that .',\n",
              " 'GUERNSEY ( Maria Kraakman - Belgium / Netherlands 2005 ). The mousy Maria Kraakman plays Anna , a woman in her thirties , who finds out her husband ( Fedja van Huet ) is cheating on her but she doesn \\' t dare to confront him . She painfully avoids any confrontation with human beings , her parents as well as her sister , so we have a main character in a feature film that doesn \\' t do much at all . We barely know anything about her background or her motivations . Just a woman who seems to be stuck in a blind alley , not just during this difficult episode of her life . She obviously suffers from something , but why do we in the audience have to suffer as well ? I almost gave up on cinema after seeing this unwatchable mess . These were a very dull and painful 90 minutes . Normally I try to avoid wasting energy on bad film making . I \\' ll take the beating and roll with the punches , but in this case a fair warning is in place . How on earth did Nanouk Leopold get funding ( in large part from publicly financed funds ) for this turkey ? Obviously , there was no script to speak off . It could be compensated by an ingenious filmmaker with cinematographic ideas or a cast with only a little more appeal . None whatsoever , just a vaguely defined concept ,\" I want to do something from a woman \\' s point of view \". The result is an insult rather than a tribute to a female perspective on life . To make things worse , there \\' s not an interesting shot to be found in the entire film . I cannot think of a cast who could have spiced this one up , but Johanna ter Steege is a ( small ) light in the dark , if possible with this dire lack of material . I \\' m trying to imagine how Leopold tried directing Maria Kraakman :\" Maria , look at the horizon , we \\' ll film you for three minutes , just express sadness \". A perfect cure for insomnia . Get a copy and watch this late at night , guaranteed too put you to sleep . Camera Obscura --- 1 / 10',\n",
              " \"It ' s hard to believe that in 1997 David Duchovny was at the top of his fame , with X - Files , one of the best sci - fi series ever , being at the top of the glory . Nine years later he is almost forgotten , and his tentatives to make it on the big screen failed miserably . I cannot even explain why , he is a fair actor , but probably his moment of fame cast him in a eternal role that takes big talent to break from . At the same time Angelina Jolie was much less known , and she was really lucky that a film like ' Playing God ' did not led her career into a dead - end . Fortunately for her ,' The Bone Collector ' and ' Girl , Interrupted ' were waiting beyond the corner , and when Lara Croft came , her career was launched . There is not too much to be told about this film . It ' s the only big screen film of Andy Wilson , and there must be a reason . All is banal and most of what happens on the screen expected in this story of an ex - doctor who saves the life of a shooting victim in a bar only to find himself working for the mob . The off - screen voice is especially bad , with a moralistic text that kills any shade of cinematographic experience from the film . You probably will not meet the film but in DVD rental stores , or on TV . Try to look for something better .\",\n",
              " '\" Laugh , Clown Laugh \" released in 1928 , stars the legendary Lon Chaney as a circus clown named Tito . Tito has raised a foundling ( a young and beautiful Loretta Young ) to adulthood and names her Simonetta . Tito has raised the girl in the circus life , and she has become an accomplished ballerina . While Chaney gives his usual great performance , I could not get past the fact that Tito , now well into middle age , has the hots for the young Simonetta . Although he is not her biological father , he has raised her like a daughter . That kind of \" ick \" factor permeates throughout the film . Tito competes for Simonetta \\' s affections with a young and handsome \\' Count \\' Luigi ( Nils Asther ). Simonetta clearly falls for the young man , but feels guilt about abandoning Tito ( out of loyalty , not romantic love ). The whole premise of the film is ridiculous , and I find it amazing that no one in the film tells Tito what a stupid old fool he is being ( until he reveals it himself at the end ). The film is noteworthy only because of Loretta Young , who would go on to have a great career . While I adore Chaney \\' s brilliance as an actor , this whole film seems off to me and just downright creepy .']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTXoWIVavvhI",
        "colab_type": "text"
      },
      "source": [
        "## Conclusion and more ideas for experiments:\n",
        "- Spoiler: **Even though the textual features use numbers, the autoencoder found them to not be so much frequent and decided they are the biggest anomalies.**\n",
        "- Real life purpose of this autoencoder could then be: **To find a text, that has unusual distribution of characters.**\n",
        "  - Could be upgraded to ignore numbers altogether, then it would process only text and find the outliers.\n",
        "  - *Remember, this is just an example with easiest autoencoder architecture. For real life applications, different architectures and embeddings/ character models should be used. Also it is possible to use a trained model and inner representation can be its last layer.*\n",
        "  \n",
        "Ways to experiment with the code:\n",
        "- The code can be tried out with embeddings\n",
        "- Character level architectures can be used\n",
        "- Varying the parameters can lead the model to perform differently\n",
        "- Or empolying different model \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25E4cqlx_UR5",
        "colab_type": "text"
      },
      "source": [
        "### When we know the purpose of the autoencoder, we can search the training set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaSo9c8p91My",
        "colab_type": "code",
        "outputId": "91e74ca8-eb73-45db-e869-f712e9706475",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "print(\"Give me sentence with this distribution of o's\")\n",
        "print(\"\")\n",
        "inspect_custom_sentence(u\"Noooooooo! I use a looooot of Ooooooos!\")\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "print(\"Give me sentence with numbers inside\")\n",
        "print(\"\")\n",
        "inspect_custom_sentence(u\"1 2 3 4 5 6 7 8 9 10 11 ... You know that iam called the Count! Because I really love to count!\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Give me sentence with this distribution of o's\n",
            "\n",
            "Reconstructed custom sentence (only using vocabulary): \n",
            "\n",
            " \n",
            " --Original sentence reconstructed just from vocabulary: \n",
            "cookbook ! i use a lookout of sooooo ! ! ! ! ! ! ! ! ! ! ! !\n",
            "--Predicted sentence reconstructed by autoencoder AND vocabulary: \n",
            "monopoly ! i use a lookout of sooooo ! h ! ! o s a ! o t o !\n",
            "--mse: 6.790060688650005e-05; ((different))\n",
            "\n",
            "Most similar sentence in trained encoder's representation: \n",
            "Somebody owes Ang Lee an apology . Actually , a lot of people do . And I ' ll start\n",
            "\n",
            "\n",
            "\n",
            "Give me sentence with numbers inside\n",
            "\n",
            "Reconstructed custom sentence (only using vocabulary): \n",
            "\n",
            " \n",
            " --Original sentence reconstructed just from vocabulary: \n",
            "1 2 3 4 5 6 7 8 9 10 11 ;) you know that aim called the count !\n",
            "--Predicted sentence reconstructed by autoencoder AND vocabulary: \n",
            "21 9 9 9 9 1 7 8 8 25 31 ! yo one thaw ai called the count w\n",
            "--mse: 0.00014884778907656263; ((different))\n",
            "\n",
            "Most similar sentence in trained encoder's representation: \n",
            "The movie deserves 2 / 10 . 1 . 5 stars for the girl ,( I ' m sorry I\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jV1qrG_V-82b",
        "colab_type": "code",
        "outputId": "4b6d1839-303f-4dbe-fe0b-5f868b3cb0a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "print(\"Give me sentence to train my pronounciation!\")\n",
        "print(\"\")\n",
        "inspect_custom_sentence(u\"qwrt qwrt qwrt qwrt qwrt qwrt qwrt q w r t q w r t q w r t\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Give me sentence to train my pronounciation!\n",
            "\n",
            "Reconstructed custom sentence (only using vocabulary): \n",
            "\n",
            " \n",
            " --Original sentence reconstructed just from vocabulary: \n",
            "waqt waqt waqt waqt waqt waqt waqt q w r t q w r t q w r t !\n",
            "--Predicted sentence reconstructed by autoencoder AND vocabulary: \n",
            "whit wore west west wire twin wait t w r t b w r t i w r t w\n",
            "--mse: 3.4385971133244184e-05; ((different))\n",
            "\n",
            "Most similar sentence in trained encoder's representation: \n",
            "Many people here say that this show is for kids only . Hm , when I was a kid (\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOMlOGRqFo8n",
        "colab_type": "text"
      },
      "source": [
        "# Thank you!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWJbvqjKEiZ2",
        "colab_type": "text"
      },
      "source": [
        "Links for literature and more examples (not only autoencoders, but also other visualizations used here):   \n",
        "\n",
        "\n",
        "https://blog.keras.io/building-autoencoders-in-keras.html  \n",
        "https://lvdmaaten.github.io/tsne/  \n",
        "https://github.com/lvdmaaten/bhtsne/  \n",
        "https://cs224d.stanford.edu/reports/OshriBarak.pdf  \n",
        "https://hackernoon.com/how-to-autoencode-your-pok%C3%A9mon-6b0f5c7b7d97   \n",
        "https://datascience.stackexchange.com/questions/29527/which-type-auto-encoder-gives-best-results-for-text   \n",
        "https://www.reddit.com/r/MachineLearning/comments/2em084/el5_what_are_autoencoders_used_for/  \n",
        "https://www.siarez.com/projects/variational-autoencoder  \n",
        "IMDB dataset for sentient:\n",
        "https://github.com/rossumai/mlprague18-nlp/blob/master/IMDB%20Sentiment.ipynb\n",
        "  \n",
        "  Bonus for everybody - colab notebook with character model (convolutional autoencoder): https://colab.research.google.com/drive/1DfLYljazmkxAwBCRt1AHbdtBU3xV0lPr ;) "
      ]
    }
  ]
}