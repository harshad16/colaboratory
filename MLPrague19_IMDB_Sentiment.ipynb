{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLPrague19 IMDB Sentiment.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "DtUaOoZf-9RC",
        "f56NxPuV-9SZ"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/martinpovolny/colaboratory/blob/master/MLPrague19_IMDB_Sentiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQpja1DZ-9Ph",
        "colab_type": "text"
      },
      "source": [
        "# Sentiment Analysis on IMDb Reviews"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DG1vlcCxUwqj",
        "colab_type": "text"
      },
      "source": [
        "Welcome to google collab! If you are not familiar with the collab notebooks, I hope You will be positively surprised :)\n",
        "\n",
        "Please:\n",
        "\n",
        "- Copy this notebook into Your own drive (File->Save a copy to drive)\n",
        "- Look into this original notebook any way you wish, it does contain our saved run\n",
        "- Feel free to select Runtime->Change runtime type into a GPU accelerated workstation :)\n",
        "- Run it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FPVcrx9-9Pm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function, division"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPWLzHje-9Ps",
        "colab_type": "text"
      },
      "source": [
        "Download and extract the IMDB sentiment dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abO-VAHX_hF3",
        "colab_type": "code",
        "outputId": "33f6c12d-bd33-44d4-d55b-dffc606349de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!    wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "!    tar xfz aclImdb_v1.tar.gz"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-02-22 08:27:39--  http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
            "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 84125825 (80M) [application/x-gzip]\n",
            "Saving to: ‘aclImdb_v1.tar.gz’\n",
            "\n",
            "aclImdb_v1.tar.gz   100%[===================>]  80.23M  19.8MB/s    in 6.5s    \n",
            "\n",
            "2019-02-22 08:27:50 (12.4 MB/s) - ‘aclImdb_v1.tar.gz’ saved [84125825/84125825]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQXlpBLB-9Pv",
        "colab_type": "text"
      },
      "source": [
        "First, we pre-process the dataset, converting each review to a sequence of word index numbers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3CrPOmM-9Pw",
        "colab_type": "code",
        "outputId": "dde63e36-60e7-449c-800c-e67295f40f91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Vocabulary: All words used, starting by the most frequent\n",
        "with open('aclImdb/imdb.vocab') as f:\n",
        "    vocab = [word.rstrip() for word in f]\n",
        "    # Keep only most frequent 5000 words rather than all 90000\n",
        "    # Just saving memory - the long tail occurs too few times\n",
        "    # for the model to learn anything anyway\n",
        "    vocab = vocab[:5000]\n",
        "    print('%d words in vocabulary' % (len(vocab),))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5000 words in vocabulary\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dh3XRMRf-9P3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "def text_tokens(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(\"\\\\s\", \" \", text)\n",
        "    text = re.sub(\"[^a-zA-Z' ]\", \"\", text)\n",
        "    tokens = text.split(' ')\n",
        "    return tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDwrjCef-9P7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "def load_dataset(dirname):\n",
        "    X, y = [], []\n",
        "    # Review files: neg/0_3.txt neg/10000_4.txt neg/10001_4.txt ...\n",
        "    for y_val, y_label in enumerate(['neg', 'pos']):\n",
        "        y_dir = os.path.join(dirname, y_label)\n",
        "        for fname in os.listdir(y_dir):\n",
        "            fpath = os.path.join(y_dir, fname)\n",
        "            # print('\\r' + fpath + '   ', end='')\n",
        "            with open(fpath) as f:\n",
        "                tokens = text_tokens(f.read())\n",
        "            X.append(tokens)\n",
        "            y.append(y_val)  # 0 for 'neg', 1 for 'pos'\n",
        "    print()\n",
        "    return X, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Dk5yi6O7-9P_",
        "colab_type": "code",
        "outputId": "77aee3a8-2d4d-4993-bd67-92e2a6e638ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "X_train, y_train = load_dataset('aclImdb/train/')\n",
        "\n",
        "# We are cheating here - this is a test set, not a validation set.\n",
        "# This is just to make results quickly comparable to outside results\n",
        "# during the tutorial, but you should normally never use the test set\n",
        "# during training, of course!\n",
        "X_val, y_val = load_dataset('aclImdb/test/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "()\n",
            "()\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0Kyi8xV-9QE",
        "colab_type": "code",
        "outputId": "05654a5b-ea48-4091-8f49-7d913acab920",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(X_train), len(X_val)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 25000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QoLumL04-9QK",
        "colab_type": "text"
      },
      "source": [
        "## Bag-of-words Linear Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOQo5OP_-9QL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bow_onehot_vector(tokens):\n",
        "    vector = [0] * len(vocab)\n",
        "    for t in tokens:\n",
        "        try:\n",
        "            vector[vocab.index(t)] = 1\n",
        "        except:\n",
        "            pass  # ignore missing words\n",
        "    return vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpSiUfNh-9QP",
        "colab_type": "code",
        "outputId": "38a362bc-6b33-4cf9-ea1a-ede8d739f5a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "X_bow_train = [bow_onehot_vector(x) for x in tqdm(X_train)]\n",
        "X_bow_val = [bow_onehot_vector(x) for x in tqdm(X_val)]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 25000/25000 [01:26<00:00, 289.79it/s]\n",
            "100%|██████████| 25000/25000 [01:25<00:00, 291.69it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxZY20nQ-9QU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def best_train_history(history):\n",
        "    best_epoch = np.argmax(history.history['val_acc'])\n",
        "    print('Accuracy (epoch %d): %.4f train, %.4f val' % \\\n",
        "          (best_epoch + 1, history.history['acc'][best_epoch], history.history['val_acc'][best_epoch]))\n",
        "# (Note that sentiment.model is the state after the last epoch rather than best epoch!\n",
        "# Use ModelCheckpointer to restore the best epoch.)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "slkvuH-s-9Qd",
        "colab_type": "code",
        "outputId": "7b89fcc8-b92a-4470-c124-520c0e57d109",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 768
        }
      },
      "source": [
        "from keras.layers import Activation, Dense, Input\n",
        "from keras.models import Model\n",
        "import numpy as np\n",
        "\n",
        "class BOWSentimentModel(object):\n",
        "    def __init__(self):\n",
        "        bow = Input(shape=(len(vocab),), name='bow_input')\n",
        "        # weights of all inputs\n",
        "        sentiment = Dense(1)(bow)\n",
        "        # normalize to [0, 1] range\n",
        "        sentiment = Activation('sigmoid')(sentiment)\n",
        "\n",
        "        self.model = Model(inputs=[bow], outputs=[sentiment])\n",
        "        self.model.summary()\n",
        "        self.model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    def train(self, X, y, X_val, y_val):\n",
        "        print('Fitting...')\n",
        "        return self.model.fit(np.array(X), y, validation_data=(np.array(X_val), y_val), epochs=10, verbose=1)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.model.predict(np.array(X))\n",
        "    \n",
        "sentiment = BOWSentimentModel()\n",
        "history = sentiment.train(X_bow_train, y_train, X_bow_val, y_val)\n",
        "best_train_history(history)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bow_input (InputLayer)       (None, 5000)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 5001      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 5,001\n",
            "Trainable params: 5,001\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Fitting...\n",
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/10\n",
            "25000/25000 [==============================] - 7s 283us/step - loss: 0.4559 - acc: 0.8312 - val_loss: 0.3653 - val_acc: 0.8686\n",
            "Epoch 2/10\n",
            "25000/25000 [==============================] - 5s 182us/step - loss: 0.3147 - acc: 0.8857 - val_loss: 0.3189 - val_acc: 0.8778\n",
            "Epoch 3/10\n",
            "25000/25000 [==============================] - 5s 184us/step - loss: 0.2733 - acc: 0.9001 - val_loss: 0.3015 - val_acc: 0.8809\n",
            "Epoch 4/10\n",
            "25000/25000 [==============================] - 5s 182us/step - loss: 0.2505 - acc: 0.9074 - val_loss: 0.2935 - val_acc: 0.8812\n",
            "Epoch 5/10\n",
            "25000/25000 [==============================] - 5s 183us/step - loss: 0.2350 - acc: 0.9134 - val_loss: 0.2912 - val_acc: 0.8824\n",
            "Epoch 6/10\n",
            "25000/25000 [==============================] - 5s 184us/step - loss: 0.2237 - acc: 0.9179 - val_loss: 0.2913 - val_acc: 0.8814\n",
            "Epoch 7/10\n",
            "25000/25000 [==============================] - 5s 183us/step - loss: 0.2144 - acc: 0.9218 - val_loss: 0.2925 - val_acc: 0.8804\n",
            "Epoch 8/10\n",
            "25000/25000 [==============================] - 5s 185us/step - loss: 0.2070 - acc: 0.9240 - val_loss: 0.2948 - val_acc: 0.8793\n",
            "Epoch 9/10\n",
            "25000/25000 [==============================] - 5s 184us/step - loss: 0.2009 - acc: 0.9272 - val_loss: 0.2972 - val_acc: 0.8781\n",
            "Epoch 10/10\n",
            "25000/25000 [==============================] - 5s 182us/step - loss: 0.1956 - acc: 0.9292 - val_loss: 0.3005 - val_acc: 0.8774\n",
            "Accuracy (epoch 5): 0.9134 train, 0.8824 val\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTe-Qt2N-9Qm",
        "colab_type": "code",
        "outputId": "ebb70fca-e743-449f-cb6c-64e0fbdff67a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "test_text = 'Good story about a backwoods community in the Ozarks around the turn of the century. Moonshine is the leading industry, fighting and funning the major form of entertainment. One day a stranger enters the community and causes a shake-up among the locals. Beautiful scenery adds much to the story.'\n",
        "test_tokens = text_tokens(test_text)\n",
        "print(test_text)\n",
        "print(sentiment.predict([bow_onehot_vector(test_tokens)])[0])\n",
        "\n",
        "test_text = 'Boring story about a backwoods community in the Ozarks around the turn of the century. Moonshine is the leading industry, fighting and funning the major form of entertainment. One day a stranger enters the community and causes a shake-up among the locals. Beautiful scenery does not add to the story.'\n",
        "test_tokens = text_tokens(test_text)\n",
        "print(test_text)\n",
        "print(sentiment.predict([bow_onehot_vector(test_tokens)])[0])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Good story about a backwoods community in the Ozarks around the turn of the century. Moonshine is the leading industry, fighting and funning the major form of entertainment. One day a stranger enters the community and causes a shake-up among the locals. Beautiful scenery adds much to the story.\n",
            "[0.7717905]\n",
            "Boring story about a backwoods community in the Ozarks around the turn of the century. Moonshine is the leading industry, fighting and funning the major form of entertainment. One day a stranger enters the community and causes a shake-up among the locals. Beautiful scenery does not add to the story.\n",
            "[0.40197328]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WBNFZb8-9Q2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot_train_history(history):\n",
        "    plt.figure()\n",
        "    plt.plot(history.history['acc'])\n",
        "    plt.plot(history.history['val_acc'])\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.legend(['acc', 'val_acc'])\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLjC737--9Q6",
        "colab_type": "code",
        "outputId": "1557e4d3-561f-47ee-a729-e1667972b8ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        }
      },
      "source": [
        "plot_train_history(history)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAFYCAYAAABKymUhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtUaOoZf-9RC",
        "colab_type": "text"
      },
      "source": [
        "### Bag-of-Words with Hidden Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "pum8HYkz-9RD",
        "colab_type": "code",
        "outputId": "ebf631cb-5e57-42dc-bd70-bd311c30ca37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        }
      },
      "source": [
        "from keras.layers import Activation, Dense, Input\n",
        "from keras.models import Model\n",
        "import numpy as np\n",
        "\n",
        "class BOWHiddenSentimentModel(object):\n",
        "    def __init__(self, N=64):\n",
        "        bow = Input(shape=(len(vocab),), name='bow_input')\n",
        "        hidden = Dense(N, activation='tanh')(bow)\n",
        "        sentiment = Dense(1, activation='sigmoid')(hidden)\n",
        "\n",
        "        self.model = Model(inputs=[bow], outputs=[sentiment])\n",
        "        self.model.summary()\n",
        "        self.model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    def train(self, X, y, X_val, y_val):\n",
        "        print('Fitting...')\n",
        "        return self.model.fit(np.array(X), y, validation_data=(np.array(X_val), y_val), epochs=10, verbose=1)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.model.predict(np.array(X))\n",
        "    \n",
        "sentiment = BOWHiddenSentimentModel()\n",
        "history = sentiment.train(X_bow_train, y_train, X_bow_val, y_val)\n",
        "best_train_history(history)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bow_input (InputLayer)       (None, 5000)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                320064    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 320,129\n",
            "Trainable params: 320,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Fitting...\n",
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/10\n",
            "25000/25000 [==============================] - 7s 273us/step - loss: 0.3308 - acc: 0.8584 - val_loss: 0.2937 - val_acc: 0.8756\n",
            "Epoch 2/10\n",
            "25000/25000 [==============================] - 5s 210us/step - loss: 0.2346 - acc: 0.9029 - val_loss: 0.3041 - val_acc: 0.8717\n",
            "Epoch 3/10\n",
            "25000/25000 [==============================] - 5s 209us/step - loss: 0.2013 - acc: 0.9188 - val_loss: 0.3298 - val_acc: 0.8638\n",
            "Epoch 4/10\n",
            "25000/25000 [==============================] - 5s 208us/step - loss: 0.1769 - acc: 0.9296 - val_loss: 0.3412 - val_acc: 0.8636\n",
            "Epoch 5/10\n",
            "25000/25000 [==============================] - 5s 208us/step - loss: 0.1496 - acc: 0.9406 - val_loss: 0.3723 - val_acc: 0.8613\n",
            "Epoch 6/10\n",
            "25000/25000 [==============================] - 5s 207us/step - loss: 0.1209 - acc: 0.9554 - val_loss: 0.4289 - val_acc: 0.8551\n",
            "Epoch 7/10\n",
            "25000/25000 [==============================] - 5s 209us/step - loss: 0.0903 - acc: 0.9687 - val_loss: 0.4633 - val_acc: 0.8547\n",
            "Epoch 8/10\n",
            "25000/25000 [==============================] - 5s 209us/step - loss: 0.0630 - acc: 0.9805 - val_loss: 0.5212 - val_acc: 0.8524\n",
            "Epoch 9/10\n",
            "25000/25000 [==============================] - 5s 208us/step - loss: 0.0386 - acc: 0.9906 - val_loss: 0.5586 - val_acc: 0.8504\n",
            "Epoch 10/10\n",
            "25000/25000 [==============================] - 5s 208us/step - loss: 0.0227 - acc: 0.9955 - val_loss: 0.6431 - val_acc: 0.8503\n",
            "Accuracy (epoch 1): 0.8584 train, 0.8756 val\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UNgXwqO-9RQ",
        "colab_type": "code",
        "outputId": "c6ef212a-a12b-4e60-9c04-f527f8c9fbc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        }
      },
      "source": [
        "plot_train_history(history)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAFYCAYAAABKymUhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K834B3Rx-9Ra",
        "colab_type": "text"
      },
      "source": [
        "Overfitting!  Ideas:\n",
        "  * Apply dropout\n",
        "  * L2-regularize the weights of the hidden layer\n",
        "  * Different N values?\n",
        "  * Multiple hidden layers, with different activation?\n",
        "  * tf-idf !\n",
        "  \n",
        "Can anyone fix the bag-of-words model?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "BvC5o3eH-9Rc",
        "colab_type": "code",
        "outputId": "fff25155-b7c2-49c6-8c21-91921490e95d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        }
      },
      "source": [
        "from keras.layers import Activation, Dense, Dropout, Input\n",
        "from keras.models import Model\n",
        "from keras import regularizers\n",
        "import numpy as np\n",
        "\n",
        "class BOWHiddenRegularizedSentimentModel(object):\n",
        "    def __init__(self, N=128):\n",
        "        bow = Input(shape=(len(vocab),), name='bow_input')\n",
        "        hidden = Dropout(0.5)(Dense(N, kernel_regularizer=regularizers.l2(1e-3))(bow))\n",
        "        sentiment = Dense(1, activation='sigmoid')(hidden)\n",
        "\n",
        "        self.model = Model(inputs=[bow], outputs=[sentiment])\n",
        "        self.model.summary()\n",
        "        self.model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    def train(self, X, y, X_val, y_val):\n",
        "        print('Fitting...')\n",
        "        return self.model.fit(np.array(X), y, validation_data=(np.array(X_val), y_val), epochs=10, verbose=1)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.model.predict(np.array(X))\n",
        "    \n",
        "sentiment = BOWHiddenRegularizedSentimentModel()\n",
        "history = sentiment.train(X_bow_train, y_train, X_bow_val, y_val)\n",
        "best_train_history(history)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bow_input (InputLayer)       (None, 5000)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 128)               640128    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 640,257\n",
            "Trainable params: 640,257\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Fitting...\n",
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/10\n",
            "25000/25000 [==============================] - 7s 263us/step - loss: 0.4913 - acc: 0.8482 - val_loss: 0.4456 - val_acc: 0.8690\n",
            "Epoch 2/10\n",
            "25000/25000 [==============================] - 7s 262us/step - loss: 0.4343 - acc: 0.8779 - val_loss: 0.4498 - val_acc: 0.8642\n",
            "Epoch 3/10\n",
            "25000/25000 [==============================] - 6s 240us/step - loss: 0.4235 - acc: 0.8752 - val_loss: 0.4339 - val_acc: 0.8686\n",
            "Epoch 4/10\n",
            "25000/25000 [==============================] - 6s 241us/step - loss: 0.4145 - acc: 0.8798 - val_loss: 0.4326 - val_acc: 0.8662\n",
            "Epoch 5/10\n",
            "25000/25000 [==============================] - 6s 241us/step - loss: 0.4072 - acc: 0.8824 - val_loss: 0.4248 - val_acc: 0.8721\n",
            "Epoch 6/10\n",
            "25000/25000 [==============================] - 6s 241us/step - loss: 0.4006 - acc: 0.8815 - val_loss: 0.4210 - val_acc: 0.8724\n",
            "Epoch 7/10\n",
            "25000/25000 [==============================] - 6s 241us/step - loss: 0.3972 - acc: 0.8854 - val_loss: 0.4236 - val_acc: 0.8678\n",
            "Epoch 8/10\n",
            "25000/25000 [==============================] - 6s 240us/step - loss: 0.3886 - acc: 0.8856 - val_loss: 0.4173 - val_acc: 0.8681\n",
            "Epoch 9/10\n",
            "25000/25000 [==============================] - 6s 241us/step - loss: 0.3855 - acc: 0.8865 - val_loss: 0.4579 - val_acc: 0.8558\n",
            "Epoch 10/10\n",
            "25000/25000 [==============================] - 6s 240us/step - loss: 0.3814 - acc: 0.8856 - val_loss: 0.4087 - val_acc: 0.8700\n",
            "Accuracy (epoch 6): 0.8815 train, 0.8724 val\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUfCSWU3-9Rh",
        "colab_type": "text"
      },
      "source": [
        "## GloVe-based Model (let's start with averaging)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwWSvDJK-9Rj",
        "colab_type": "text"
      },
      "source": [
        "Download and extract the official pre-trained GloVe matrix:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oh_CHorSBRjN",
        "colab_type": "code",
        "outputId": "04c880a9-07ad-4f3b-a4da-141367b4d669",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "! wget https://nlp.stanford.edu/data/glove.6B.zip\n",
        "! unzip glove.6B.zip\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-02-22 09:24:32--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  6.55MB/s    in 3m 37s  \n",
            "\n",
            "2019-02-22 09:28:10 (3.78 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_VJISCtBX5p",
        "colab_type": "text"
      },
      "source": [
        "We decided to use GloVe over word2vec as in our experience, GloVe carries word semantics better and works better in semantic-sensitive tasks.  But the difference is not huge."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHrfYbfV-9Rq",
        "colab_type": "text"
      },
      "source": [
        "### Loading GloVe vocabulary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgWxaO8I-9Rs",
        "colab_type": "text"
      },
      "source": [
        "You may need to restart your kernel here if you don't have a lot of free memory, to get rid of the bag-of-words vectors from before."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzCS4vLE-9Ru",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Embedding dimension means how many elements each word vector has.\n",
        "# Common values are 50 and 300.  Generally, larger vectors have more\n",
        "# capacity to carry information (meaning).  But the training process\n",
        "# is slower, both vectors and further layers take more memory, and\n",
        "# there could be higher risk of overfitting.\n",
        "EMBEDDING_DIM = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pH6j5q5-9Ry",
        "colab_type": "code",
        "outputId": "8270b19c-86fa-4207-d7bd-c8520651a0ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# let's create a dictionary of each word in the pre-trained GloVe embeddings, saving its location indexes \n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "GLOVE_DIR = \".\"\n",
        "embeddings_index = {}\n",
        "f = open(os.path.join(GLOVE_DIR, 'glove.6B.%dd.txt' % EMBEDDING_DIM))\n",
        "for line in tqdm(f):\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "400000it [00:05, 76339.93it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kj-muSQo-9R4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# a matrix that is indexed by our vocabulary, containing\n",
        "# GloVe embedding for each vocabulary element\n",
        "embedding_matrix = np.zeros((len(vocab) + 1, EMBEDDING_DIM))\n",
        "for i, word in enumerate(vocab):\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        # also, [0] is reserved for padding\n",
        "        embedding_matrix[i + 1] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTqCYB5n-9R7",
        "colab_type": "text"
      },
      "source": [
        "Checking how many words have no pre-trained GloVe word embeddings:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5zua3DU-9R8",
        "colab_type": "code",
        "outputId": "3a542f3c-0e7c-4ab3-d776-a00414e7c5cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "1. * np.count_nonzero(np.all(embedding_matrix == 0, axis=1)) / len(vocab)  # OOV portion"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0076"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtQ5rl0R-9SD",
        "colab_type": "text"
      },
      "source": [
        "We are representing reviews as sequences now.  However, each sequence must have the same length on the input in Keras.  We will pad shorter sequences by zeroes from right, but what should be the maximum sequence length?  Let's find a compromise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgQLKWwJ-9SF",
        "colab_type": "code",
        "outputId": "2acc8800-fdd2-4d33-e442-22e4e3c7626b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "lengths = sorted([len(X) for X in X_train])\n",
        "percentile = 0.90\n",
        "seq_cutoff = lengths[int(len(lengths)*percentile)]\n",
        "print('Longest: %d, Average: %f, Median: %d, %d%% percentile: %d tokens' % (lengths[-1], np.mean(lengths), lengths[int(len(lengths)*0.5)], percentile*100, seq_cutoff))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Longest: 2470, Average: 233.778560, Median: 174, 90% percentile: 458 tokens\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTymg3Ex-9SP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vocab_indices_vector(tokens):\n",
        "    vector = [0] * seq_cutoff\n",
        "    if len(tokens) > seq_cutoff:\n",
        "        # Remove the middle\n",
        "        tokens = tokens[: seq_cutoff // 2] + ['SINGLE_PADDING_IN_THE_MIDDLE'] + tokens[-seq_cutoff // 2 :]\n",
        "    for i, t in enumerate(tokens):\n",
        "        try:\n",
        "            vector[i] = vocab.index(t) + 1  # reserving 0 for padding\n",
        "        except:\n",
        "            pass  # ignore missing words\n",
        "    return vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhwByKqy-9SU",
        "colab_type": "code",
        "outputId": "c2c34745-12b1-4676-daca-2607052eb75b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "X_indices_train = [vocab_indices_vector(x) for x in tqdm(X_train)]\n",
        "X_indices_val = [vocab_indices_vector(x) for x in tqdm(X_val)]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 25000/25000 [01:20<00:00, 311.61it/s]\n",
            "100%|██████████| 25000/25000 [01:19<00:00, 316.23it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f56NxPuV-9SZ",
        "colab_type": "text"
      },
      "source": [
        "### GloVe averaging model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "SdZZveHW-9Sa",
        "colab_type": "code",
        "outputId": "2e25710b-fad8-4ed9-df75-4fa9cacbd201",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        }
      },
      "source": [
        "from keras.layers import Activation, GlobalAveragePooling1D, Dense, Embedding, Input\n",
        "from keras.models import Model\n",
        "import numpy as np\n",
        "\n",
        "class GloveAvgSentimentModel(object):\n",
        "    def __init__(self):\n",
        "        self.model = self.create()\n",
        "        self.model.summary()\n",
        "        self.model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "        \n",
        "    def create(self):\n",
        "        seq_indices = Input(shape=(seq_cutoff,), name='seq_input')                    \n",
        "        seq_embedded = Embedding(input_dim=len(vocab) + 1, output_dim=EMBEDDING_DIM, weights=[embedding_matrix],\n",
        "                                 input_length=seq_cutoff, trainable=False)(seq_indices)\n",
        "        avg_embedded = GlobalAveragePooling1D()(seq_embedded)\n",
        "        sentiment = Dense(1, activation='sigmoid')(avg_embedded)\n",
        "\n",
        "        return Model(inputs=[seq_indices], outputs=[sentiment])\n",
        "\n",
        "    def train(self, X, y, X_val, y_val):\n",
        "        print('Fitting...')\n",
        "        return self.model.fit(np.array(X, dtype='int32'), y,\n",
        "                              validation_data=(np.array(X_val, dtype='int32'), y_val), epochs=10, verbose=1)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.model.predict(np.array(X))\n",
        "    \n",
        "sentiment = GloveAvgSentimentModel()\n",
        "history = sentiment.train(X_indices_train, y_train, X_indices_val, y_val)\n",
        "best_train_history(history)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "seq_input (InputLayer)       (None, 458)               0         \n",
            "_________________________________________________________________\n",
            "embedding_3 (Embedding)      (None, 458, 50)           250050    \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_3 ( (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 250,101\n",
            "Trainable params: 51\n",
            "Non-trainable params: 250,050\n",
            "_________________________________________________________________\n",
            "Fitting...\n",
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/10\n",
            "25000/25000 [==============================] - 4s 153us/step - loss: 0.6875 - acc: 0.5638 - val_loss: 0.6775 - val_acc: 0.6101\n",
            "Epoch 2/10\n",
            "25000/25000 [==============================] - 4s 148us/step - loss: 0.6695 - acc: 0.6370 - val_loss: 0.6648 - val_acc: 0.6375\n",
            "Epoch 3/10\n",
            "25000/25000 [==============================] - 4s 147us/step - loss: 0.6572 - acc: 0.6557 - val_loss: 0.6545 - val_acc: 0.6516\n",
            "Epoch 4/10\n",
            "25000/25000 [==============================] - 4s 148us/step - loss: 0.6476 - acc: 0.6646 - val_loss: 0.6464 - val_acc: 0.6590\n",
            "Epoch 5/10\n",
            "25000/25000 [==============================] - 4s 148us/step - loss: 0.6396 - acc: 0.6707 - val_loss: 0.6394 - val_acc: 0.6653\n",
            "Epoch 6/10\n",
            "25000/25000 [==============================] - 4s 147us/step - loss: 0.6329 - acc: 0.6773 - val_loss: 0.6337 - val_acc: 0.6710\n",
            "Epoch 7/10\n",
            "25000/25000 [==============================] - 4s 148us/step - loss: 0.6270 - acc: 0.6819 - val_loss: 0.6289 - val_acc: 0.6740\n",
            "Epoch 8/10\n",
            "25000/25000 [==============================] - 4s 146us/step - loss: 0.6219 - acc: 0.6862 - val_loss: 0.6241 - val_acc: 0.6794\n",
            "Epoch 9/10\n",
            "25000/25000 [==============================] - 4s 146us/step - loss: 0.6173 - acc: 0.6899 - val_loss: 0.6198 - val_acc: 0.6840\n",
            "Epoch 10/10\n",
            "25000/25000 [==============================] - 4s 146us/step - loss: 0.6131 - acc: 0.6938 - val_loss: 0.6160 - val_acc: 0.6877\n",
            "Accuracy (epoch 10): 0.6938 train, 0.6877 val\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-Brswov-9Sh",
        "colab_type": "text"
      },
      "source": [
        "Questions:\n",
        "  * Predict sentiment from mean embedding, or mean sentiment from each embedding?\n",
        "  * Projection to a latent \"sentiment predictive\" vector space first?\n",
        "  \n",
        "Other ideas (for pretty much all further models):\n",
        "  * Trainable embeddings?\n",
        "  * ...what about embeddings from scratch, by the way?\n",
        "  * Just more epochs?\n",
        "\n",
        "Advanced idea:\n",
        "  * Could we visualize importance of individual words towards the predicted sentiment?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YP67FQAl-9Sh",
        "colab_type": "text"
      },
      "source": [
        "### Maximum in a \"sentiment predictive\" space"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "kReH2-iD-9Si",
        "colab_type": "code",
        "outputId": "1dfb52a5-1a3e-486e-d3aa-ca8463e4e692",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        }
      },
      "source": [
        "from keras.layers import Activation, GlobalMaxPooling1D, Dense, Embedding, Input\n",
        "from keras.models import Model\n",
        "import numpy as np\n",
        "\n",
        "class GloveHiddenMaxSentimentModel(object):\n",
        "    def __init__(self, N=64):\n",
        "        self.model = self.create(N)\n",
        "        self.model.summary()\n",
        "        self.model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "        \n",
        "    def create(self, N):\n",
        "        seq_indices = Input(shape=(seq_cutoff,), name='seq_input')                    \n",
        "        seq_embedded = Embedding(input_dim=len(vocab) + 1, output_dim=EMBEDDING_DIM, weights=[embedding_matrix],\n",
        "                                 input_length=seq_cutoff, trainable=False)(seq_indices)\n",
        "        seq_hidden = Dense(N, activation='tanh')(seq_embedded)\n",
        "        max_hidden = GlobalMaxPooling1D()(seq_hidden)\n",
        "        sentiment = Dense(1, activation='sigmoid')(max_hidden)\n",
        "\n",
        "        return Model(inputs=[seq_indices], outputs=[sentiment])\n",
        "\n",
        "    def train(self, X, y, X_val, y_val):\n",
        "        print('Fitting...')\n",
        "        return self.model.fit(np.array(X, dtype='int32'), y,\n",
        "                              validation_data=(np.array(X_val, dtype='int32'), y_val), epochs=10, verbose=1)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.model.predict(np.array(X))\n",
        "    \n",
        "sentiment = GloveHiddenMaxSentimentModel()\n",
        "history = sentiment.train(X_indices_train, y_train, X_indices_val, y_val)\n",
        "best_train_history(history)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "seq_input (InputLayer)       (None, 458)               0         \n",
            "_________________________________________________________________\n",
            "embedding_4 (Embedding)      (None, 458, 50)           250050    \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 458, 64)           3264      \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_1 (Glob (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 253,379\n",
            "Trainable params: 3,329\n",
            "Non-trainable params: 250,050\n",
            "_________________________________________________________________\n",
            "Fitting...\n",
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/10\n",
            "25000/25000 [==============================] - 5s 214us/step - loss: 0.5497 - acc: 0.7342 - val_loss: 0.4656 - val_acc: 0.7868\n",
            "Epoch 2/10\n",
            "25000/25000 [==============================] - 5s 207us/step - loss: 0.4328 - acc: 0.8084 - val_loss: 0.4215 - val_acc: 0.8115\n",
            "Epoch 3/10\n",
            "25000/25000 [==============================] - 5s 206us/step - loss: 0.3980 - acc: 0.8270 - val_loss: 0.3991 - val_acc: 0.8208\n",
            "Epoch 4/10\n",
            "25000/25000 [==============================] - 5s 205us/step - loss: 0.3752 - acc: 0.8359 - val_loss: 0.3891 - val_acc: 0.8254\n",
            "Epoch 5/10\n",
            "25000/25000 [==============================] - 5s 206us/step - loss: 0.3571 - acc: 0.8473 - val_loss: 0.3887 - val_acc: 0.8244\n",
            "Epoch 6/10\n",
            "25000/25000 [==============================] - 5s 204us/step - loss: 0.3455 - acc: 0.8522 - val_loss: 0.3940 - val_acc: 0.8191\n",
            "Epoch 7/10\n",
            "25000/25000 [==============================] - 5s 207us/step - loss: 0.3338 - acc: 0.8568 - val_loss: 0.3773 - val_acc: 0.8309\n",
            "Epoch 8/10\n",
            "25000/25000 [==============================] - 5s 205us/step - loss: 0.3250 - acc: 0.8609 - val_loss: 0.3739 - val_acc: 0.8320\n",
            "Epoch 9/10\n",
            "25000/25000 [==============================] - 5s 204us/step - loss: 0.3185 - acc: 0.8636 - val_loss: 0.3716 - val_acc: 0.8332\n",
            "Epoch 10/10\n",
            "25000/25000 [==============================] - 5s 204us/step - loss: 0.3132 - acc: 0.8681 - val_loss: 0.3889 - val_acc: 0.8253\n",
            "Accuracy (epoch 9): 0.8636 train, 0.8332 val\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSIrpXsu-9Sm",
        "colab_type": "text"
      },
      "source": [
        "Ideas:\n",
        "  * Averaging rather than maximum?\n",
        "  * Do other N values make a difference?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l32vkRE8-9Sn",
        "colab_type": "text"
      },
      "source": [
        "## Convolutions on sequences of embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "mTTc1kwo-9So",
        "colab_type": "code",
        "outputId": "699cb6a6-6a28-437c-8d22-8d3880a0052e",
        "colab": {}
      },
      "source": [
        "from keras.layers import Activation, Conv1D, Dense, Embedding, GlobalMaxPooling1D, Input\n",
        "from keras.models import Model\n",
        "import numpy as np\n",
        "\n",
        "class GloveCNNSentimentModel(object):\n",
        "    def __init__(self, N=64, size=3):\n",
        "        self.model = self.create(N, size)\n",
        "        self.model.summary()\n",
        "        self.model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "        \n",
        "    def create(self, N, size):\n",
        "        seq_indices = Input(shape=(seq_cutoff,), name='seq_input') \n",
        "        seq_embedded = Embedding(input_dim=len(vocab) + 1, output_dim=EMBEDDING_DIM, weights=[embedding_matrix],\n",
        "                                 input_length=seq_cutoff, trainable=False)(seq_indices)\n",
        "        seq_conv = Conv1D(N, size, activation='tanh')(seq_embedded)\n",
        "        max_conv = GlobalMaxPooling1D()(seq_conv)\n",
        "        hidden_repr = Dense(N, activation='tanh')(max_conv)\n",
        "        sentiment = Dense(1, activation='sigmoid')(hidden_repr)\n",
        "\n",
        "        return Model(inputs=[seq_indices], outputs=[sentiment])\n",
        "\n",
        "    def train(self, X, y, X_val, y_val):\n",
        "        print('Fitting...')\n",
        "        return self.model.fit(np.array(X, dtype='int32'), y,\n",
        "                              validation_data=(np.array(X_val, dtype='int32'), y_val), epochs=10, verbose=1)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.model.predict(np.array(X))\n",
        "    \n",
        "sentiment = GloveCNNSentimentModel()\n",
        "history = sentiment.train(X_indices_train, y_train, X_indices_val, y_val)\n",
        "best_train_history(history)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "seq_input (InputLayer)       (None, 458)               0         \n",
            "_________________________________________________________________\n",
            "embedding_3 (Embedding)      (None, 458, 50)           250050    \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 456, 64)           9664      \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_2 (Glob (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 263,939\n",
            "Trainable params: 13,889\n",
            "Non-trainable params: 250,050\n",
            "_________________________________________________________________\n",
            "Fitting...\n",
            "['seq_input']\n",
            "['dense_10']\n",
            "['seq_input']\n",
            "['dense_10']\n",
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/10\n",
            "25000/25000 [==============================] - 6s 240us/step - loss: 0.4946 - acc: 0.7489 - val_loss: 0.4146 - val_acc: 0.8111\n",
            "Epoch 2/10\n",
            "25000/25000 [==============================] - 4s 168us/step - loss: 0.3692 - acc: 0.8385 - val_loss: 0.3745 - val_acc: 0.8340\n",
            "Epoch 3/10\n",
            "25000/25000 [==============================] - 4s 167us/step - loss: 0.3295 - acc: 0.8583 - val_loss: 0.4009 - val_acc: 0.8249\n",
            "Epoch 4/10\n",
            "25000/25000 [==============================] - 4s 167us/step - loss: 0.3007 - acc: 0.8734 - val_loss: 0.3925 - val_acc: 0.8296\n",
            "Epoch 5/10\n",
            "25000/25000 [==============================] - 4s 167us/step - loss: 0.2730 - acc: 0.8872 - val_loss: 0.3785 - val_acc: 0.8374\n",
            "Epoch 6/10\n",
            "25000/25000 [==============================] - 4s 168us/step - loss: 0.2498 - acc: 0.8979 - val_loss: 0.3955 - val_acc: 0.8358\n",
            "Epoch 7/10\n",
            "25000/25000 [==============================] - 4s 167us/step - loss: 0.2358 - acc: 0.9030 - val_loss: 0.4073 - val_acc: 0.8319\n",
            "Epoch 8/10\n",
            "25000/25000 [==============================] - 4s 168us/step - loss: 0.2138 - acc: 0.9129 - val_loss: 0.5104 - val_acc: 0.8086\n",
            "Epoch 9/10\n",
            "25000/25000 [==============================] - 4s 166us/step - loss: 0.2093 - acc: 0.9157 - val_loss: 0.4437 - val_acc: 0.8274\n",
            "Epoch 10/10\n",
            "25000/25000 [==============================] - 4s 168us/step - loss: 0.1935 - acc: 0.9227 - val_loss: 0.4514 - val_acc: 0.8310\n",
            "Accuracy (epoch 5): 0.8872 train, 0.8374 val\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwdxR4-K-9Su",
        "colab_type": "text"
      },
      "source": [
        "This model still sucks.  What problems does it have?\n",
        "\n",
        "But the model below is awesome.  (Stolen from Keras' `examples/imdb_cnn.py`.)\n",
        "  * What are the differences to the model above?\n",
        "  * What exactly makes it so awesome?\n",
        "  * Did we beat the bag-of-words baseline yet?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "3J5yeVx5-9Sv",
        "colab_type": "code",
        "outputId": "41181aa5-9c68-4247-ccf4-73ee950631a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        }
      },
      "source": [
        "from keras.layers import Activation, Conv1D, Dense, Dropout, Embedding, GlobalMaxPooling1D, Input\n",
        "from keras.models import Model\n",
        "import numpy as np\n",
        "\n",
        "class GloveCNNAwesomeSentimentModel(object):\n",
        "    def __init__(self, N=256, size=3):\n",
        "        self.model = self.create(N, size)\n",
        "        self.model.summary()\n",
        "        self.model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "        \n",
        "    def create(self, N, size):\n",
        "        seq_indices = Input(shape=(seq_cutoff,), name='seq_input') \n",
        "        seq_embedded = Embedding(input_dim=len(vocab) + 1, output_dim=EMBEDDING_DIM,\n",
        "                                 input_length=seq_cutoff)(seq_indices)\n",
        "        seq_conv = Conv1D(N, size, activation='relu')(Dropout(0.2)(seq_embedded))\n",
        "        max_conv = GlobalMaxPooling1D()(seq_conv)\n",
        "        hidden_repr = Dense(N, activation='relu')(max_conv)\n",
        "        sentiment = Dense(1, activation='sigmoid')(Dropout(0.2)(hidden_repr))\n",
        "\n",
        "        return Model(inputs=[seq_indices], outputs=[sentiment])\n",
        "\n",
        "    def train(self, X, y, X_val, y_val):\n",
        "        print('Fitting...')\n",
        "        return self.model.fit(np.array(X, dtype='int32'), y,\n",
        "                              validation_data=(np.array(X_val, dtype='int32'), y_val), epochs=10, verbose=1)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.model.predict(np.array(X))\n",
        "    \n",
        "sentiment = GloveCNNAwesomeSentimentModel()\n",
        "history = sentiment.train(X_indices_train, y_train, X_indices_val, y_val)\n",
        "best_train_history(history)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "seq_input (InputLayer)       (None, 458)               0         \n",
            "_________________________________________________________________\n",
            "embedding_7 (Embedding)      (None, 458, 50)           250050    \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 458, 50)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_4 (Conv1D)            (None, 456, 256)          38656     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_5 (Glob (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 354,755\n",
            "Trainable params: 354,755\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Fitting...\n",
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/10\n",
            "25000/25000 [==============================] - 12s 473us/step - loss: 0.4135 - acc: 0.7934 - val_loss: 0.3009 - val_acc: 0.8726\n",
            "Epoch 2/10\n",
            "25000/25000 [==============================] - 11s 423us/step - loss: 0.2450 - acc: 0.9028 - val_loss: 0.2737 - val_acc: 0.8852\n",
            "Epoch 3/10\n",
            "25000/25000 [==============================] - 11s 425us/step - loss: 0.1769 - acc: 0.9316 - val_loss: 0.2845 - val_acc: 0.8875\n",
            "Epoch 4/10\n",
            "25000/25000 [==============================] - 11s 425us/step - loss: 0.1213 - acc: 0.9550 - val_loss: 0.3197 - val_acc: 0.8808\n",
            "Epoch 5/10\n",
            "25000/25000 [==============================] - 11s 423us/step - loss: 0.0846 - acc: 0.9682 - val_loss: 0.3408 - val_acc: 0.8839\n",
            "Epoch 6/10\n",
            "25000/25000 [==============================] - 11s 424us/step - loss: 0.0608 - acc: 0.9786 - val_loss: 0.4036 - val_acc: 0.8765\n",
            "Epoch 7/10\n",
            "25000/25000 [==============================] - 11s 424us/step - loss: 0.0508 - acc: 0.9817 - val_loss: 0.4670 - val_acc: 0.8781\n",
            "Epoch 8/10\n",
            "25000/25000 [==============================] - 11s 423us/step - loss: 0.0434 - acc: 0.9844 - val_loss: 0.4833 - val_acc: 0.8730\n",
            "Epoch 9/10\n",
            "25000/25000 [==============================] - 11s 423us/step - loss: 0.0378 - acc: 0.9866 - val_loss: 0.5276 - val_acc: 0.8780\n",
            "Epoch 10/10\n",
            "25000/25000 [==============================] - 11s 424us/step - loss: 0.0324 - acc: 0.9886 - val_loss: 0.5617 - val_acc: 0.8806\n",
            "Accuracy (epoch 3): 0.9316 train, 0.8875 val\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQOd6dhh-9S8",
        "colab_type": "text"
      },
      "source": [
        "Can we make the model more awesome yet?\n",
        "\n",
        "Ideas:\n",
        "  * So what about the Glove pretrained embeddings?\n",
        "  * Project the embeddings to a more convolution-friendly space?\n",
        "  * Average pooling instead of max?\n",
        "  * Is 300D embedding better?\n",
        "  \n",
        "Advanced ideas:\n",
        "  * What about _both_ average and max pooling?\n",
        "  * `relu` activation is popular in computer vision CNNs instead of `tanh`.\n",
        "  * Some people recommend `rmsprop` optimizer rather than `adam` for CNNs. Does it matter?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcuz_-sZ-9S9",
        "colab_type": "text"
      },
      "source": [
        "## Recurrence on sequences of embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "BWQFFtaz-9S_",
        "colab_type": "code",
        "outputId": "c95af15b-a8fe-4358-ec29-26db406b69f5",
        "colab": {}
      },
      "source": [
        "from keras.layers import Activation, Dense, Embedding, GRU, Input\n",
        "from keras.models import Model\n",
        "import numpy as np\n",
        "\n",
        "class GloveGRUSentimentModel(object):\n",
        "    def __init__(self, N=64):\n",
        "        self.model = self.create(N)\n",
        "        self.model.summary()\n",
        "        self.model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "        \n",
        "    def create(self, N):\n",
        "        seq_indices = Input(shape=(seq_cutoff,), name='seq_input') \n",
        "        seq_embedded = Embedding(input_dim=len(vocab) + 1, output_dim=EMBEDDING_DIM, weights=[embedding_matrix],\n",
        "                                 input_length=seq_cutoff, trainable=False)(seq_indices)\n",
        "        recursive_repr = GRU(N)(seq_embedded)\n",
        "        sentiment = Dense(1, activation='sigmoid')(recursive_repr)\n",
        "\n",
        "        return Model(inputs=[seq_indices], outputs=[sentiment])\n",
        "\n",
        "    def train(self, X, y, X_val, y_val):\n",
        "        print('Fitting...')\n",
        "        return self.model.fit(np.array(X, dtype='int32'), y,\n",
        "                              validation_data=(np.array(X_val, dtype='int32'), y_val), epochs=10, verbose=1)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.model.predict(np.array(X))\n",
        "    \n",
        "sentiment = GloveGRUSentimentModel()\n",
        "history = sentiment.train(X_indices_train, y_train, X_indices_val, y_val)\n",
        "best_train_history(history)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "seq_input (InputLayer)       (None, 458)               0         \n",
            "_________________________________________________________________\n",
            "embedding_5 (Embedding)      (None, 458, 50)           250050    \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (None, 64)                22080     \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 272,195\n",
            "Trainable params: 22,145\n",
            "Non-trainable params: 250,050\n",
            "_________________________________________________________________\n",
            "Fitting...\n",
            "['seq_input']\n",
            "['dense_13']\n",
            "['seq_input']\n",
            "['dense_13']\n",
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/10\n",
            "25000/25000 [==============================] - 540s 22ms/step - loss: 0.6910 - acc: 0.5092 - val_loss: 0.6826 - val_acc: 0.5236\n",
            "Epoch 2/10\n",
            "25000/25000 [==============================] - 536s 21ms/step - loss: 0.5446 - acc: 0.6851 - val_loss: 0.4029 - val_acc: 0.8170\n",
            "Epoch 3/10\n",
            "25000/25000 [==============================] - 527s 21ms/step - loss: 0.3816 - acc: 0.8287 - val_loss: 0.3633 - val_acc: 0.8353\n",
            "Epoch 4/10\n",
            "25000/25000 [==============================] - 527s 21ms/step - loss: 0.3472 - acc: 0.8488 - val_loss: 0.3377 - val_acc: 0.8502\n",
            "Epoch 5/10\n",
            "25000/25000 [==============================] - 518s 21ms/step - loss: 0.3239 - acc: 0.8586 - val_loss: 0.3275 - val_acc: 0.8560\n",
            "Epoch 6/10\n",
            "25000/25000 [==============================] - 523s 21ms/step - loss: 0.3009 - acc: 0.8702 - val_loss: 0.3432 - val_acc: 0.8504\n",
            "Epoch 7/10\n",
            "25000/25000 [==============================] - 526s 21ms/step - loss: 0.2890 - acc: 0.8768 - val_loss: 0.3201 - val_acc: 0.8607\n",
            "Epoch 8/10\n",
            "25000/25000 [==============================] - 520s 21ms/step - loss: 0.2680 - acc: 0.8852 - val_loss: 0.3279 - val_acc: 0.8537\n",
            "Epoch 9/10\n",
            "25000/25000 [==============================] - 524s 21ms/step - loss: 0.2549 - acc: 0.8939 - val_loss: 0.3133 - val_acc: 0.8665\n",
            "Epoch 10/10\n",
            "25000/25000 [==============================] - 529s 21ms/step - loss: 0.2428 - acc: 0.9001 - val_loss: 0.3242 - val_acc: 0.8631\n",
            "Accuracy (epoch 9): 0.8939 train, 0.8665 val\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utKczfdI-9TE",
        "colab_type": "text"
      },
      "source": [
        "If you take the time to train the model, it seems to really suck after the first epoch.  What could be the problem?  (Imagine the input, and how the RNN processes it.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ey9CBLy-9TF",
        "colab_type": "text"
      },
      "source": [
        "The model below fixes the problem - how?  What is the most essential change?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "ObCeEzVF-9TI",
        "colab_type": "code",
        "outputId": "51b6dfe9-115c-4651-d2f3-a890454a970a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        }
      },
      "source": [
        "from keras.layers import Activation, Bidirectional, Dense, Embedding, GRU, Input\n",
        "from keras.models import Model\n",
        "import numpy as np\n",
        "\n",
        "class GloveGRUSentimentModel(object):\n",
        "    def __init__(self, N=64):\n",
        "        self.model = self.create(N)\n",
        "        self.model.summary()\n",
        "        self.model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "        \n",
        "    def create(self, N):\n",
        "        seq_indices = Input(shape=(seq_cutoff,), name='seq_input') \n",
        "        seq_embedded = Embedding(input_dim=len(vocab) + 1, output_dim=EMBEDDING_DIM, weights=[embedding_matrix],\n",
        "                                 input_length=seq_cutoff, mask_zero=True)(seq_indices)\n",
        "        recursive_repr = Bidirectional(GRU(N))(seq_embedded)\n",
        "        sentiment = Dense(1, activation='sigmoid')(recursive_repr)\n",
        "\n",
        "        return Model(inputs=[seq_indices], outputs=[sentiment])\n",
        "\n",
        "    def train(self, X, y, X_val, y_val):\n",
        "        print('Fitting...')\n",
        "        return self.model.fit(np.array(X, dtype='int32'), y,\n",
        "                              validation_data=(np.array(X_val, dtype='int32'), y_val), epochs=10, verbose=1,\n",
        "                             batch_size=128)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.model.predict(np.array(X))\n",
        "    \n",
        "sentiment = GloveGRUSentimentModel()\n",
        "history = sentiment.train(X_indices_train, y_train, X_indices_val, y_val)\n",
        "best_train_history(history)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "seq_input (InputLayer)       (None, 458)               0         \n",
            "_________________________________________________________________\n",
            "embedding_5 (Embedding)      (None, 458, 50)           250050    \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 128)               44160     \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 294,339\n",
            "Trainable params: 294,339\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Fitting...\n",
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/10\n",
            "25000/25000 [==============================] - 521s 21ms/step - loss: 0.5254 - acc: 0.7247 - val_loss: 0.3838 - val_acc: 0.8291\n",
            "Epoch 2/10\n",
            "25000/25000 [==============================] - 497s 20ms/step - loss: 0.3072 - acc: 0.8692 - val_loss: 0.2909 - val_acc: 0.8767\n",
            "Epoch 3/10\n",
            "25000/25000 [==============================] - 532s 21ms/step - loss: 0.2492 - acc: 0.8980 - val_loss: 0.2832 - val_acc: 0.8790\n",
            "Epoch 4/10\n",
            "25000/25000 [==============================] - 549s 22ms/step - loss: 0.2134 - acc: 0.9140 - val_loss: 0.2815 - val_acc: 0.8859\n",
            "Epoch 5/10\n",
            "25000/25000 [==============================] - 486s 19ms/step - loss: 0.1836 - acc: 0.9295 - val_loss: 0.2887 - val_acc: 0.8841\n",
            "Epoch 6/10\n",
            "25000/25000 [==============================] - 482s 19ms/step - loss: 0.1501 - acc: 0.9450 - val_loss: 0.3090 - val_acc: 0.8808\n",
            "Epoch 7/10\n",
            "25000/25000 [==============================] - 483s 19ms/step - loss: 0.1202 - acc: 0.9570 - val_loss: 0.3675 - val_acc: 0.8769\n",
            "Epoch 8/10\n",
            "25000/25000 [==============================] - 485s 19ms/step - loss: 0.0923 - acc: 0.9682 - val_loss: 0.3865 - val_acc: 0.8779\n",
            "Epoch 9/10\n",
            "25000/25000 [==============================] - 485s 19ms/step - loss: 0.0646 - acc: 0.9802 - val_loss: 0.5555 - val_acc: 0.8564\n",
            "Epoch 10/10\n",
            "25000/25000 [==============================] - 485s 19ms/step - loss: 0.0442 - acc: 0.9870 - val_loss: 0.5043 - val_acc: 0.8708\n",
            "Accuracy (epoch 4): 0.9140 train, 0.8859 val\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCXUIMyN-9TO",
        "colab_type": "text"
      },
      "source": [
        "We are overfitting.  Can we improve generalization?\n",
        "\n",
        "Ideas:\n",
        "  * `GRU(N, return_sequence=True)` would return a single output element for each input element, rather than a single output for the whole sequence.  What cool things could we use this for?\n",
        "  * Any ideas to borrow from CNNs?\n",
        "  * Could we stack multiple GRUs on top of each other?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6PUAKrA-9TR",
        "colab_type": "text"
      },
      "source": [
        "## Combining CNN and GRU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsXZBfAa-9TT",
        "colab_type": "text"
      },
      "source": [
        "Let's go wild and take a look at an even more advanced model combining several ideas.  Can you explain what's going on here? Is this madness worth it? Which further improvements might be most desirable to test?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HP3eGl6d-9TU",
        "colab_type": "code",
        "outputId": "61a7aaef-6eef-4911-d40a-e4e81c5f7764",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 921
        }
      },
      "source": [
        "from keras.layers import Activation, Bidirectional, Conv1D, Dense, Embedding, GlobalMaxPooling1D, GRU, Input, add\n",
        "from keras.models import Model\n",
        "import numpy as np\n",
        "\n",
        "class GloveCNNGRUSISentimentModel(object):\n",
        "    def __init__(self, N=64, size=3):\n",
        "        self.model = self.create(N, size)\n",
        "        self.model.summary()\n",
        "        self.model.compile(optimizer='adam', loss='binary_crossentropy', loss_weights=[0.2, 1.0], metrics=['accuracy'])\n",
        "        \n",
        "    def create(self, N, size):\n",
        "        seq_indices = Input(shape=(seq_cutoff,), name='seq_input') \n",
        "        seq_embedded = Embedding(input_dim=len(vocab) + 1, output_dim=EMBEDDING_DIM, weights=[embedding_matrix],\n",
        "                                 input_length=seq_cutoff)(seq_indices)\n",
        "        seq_hidden = Dense(N, activation='tanh')(Dropout(0.2)(seq_embedded))\n",
        "        \n",
        "        seq_conv = Conv1D(N, size, activation='tanh', padding='same')(Dropout(0.2)(seq_hidden))\n",
        "        # Residual skip-connection: The convolution just fine-tunes per-word Dense projection.\n",
        "        seq_hidden = add([seq_hidden, seq_conv])\n",
        "        \n",
        "        recursive_repr = Bidirectional(GRU(N))(seq_hidden)\n",
        "        sentiment = Dense(1, activation='sigmoid', name='sentiment')(recursive_repr)\n",
        "        \n",
        "        # Inception: Also try to make even the hidden representation good enough to predict sentiment.\n",
        "        max_hidden = GlobalMaxPooling1D()(seq_hidden)\n",
        "        sentiment_by_hidden = Dense(1, activation='sigmoid', name='sentiment_by_hidden')(max_hidden)\n",
        "\n",
        "        return Model(inputs=[seq_indices], outputs=[sentiment_by_hidden, sentiment])\n",
        "\n",
        "    def train(self, X, y, X_val, y_val):\n",
        "        print('Fitting...')\n",
        "        return self.model.fit(np.array(X, dtype='int32'), [np.array(y), np.array(y)],\n",
        "                              validation_data=(np.array(X_val, dtype='int32'),\n",
        "                                               [np.array(y_val), np.array(y_val)]),\n",
        "                              epochs=10, verbose=1)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.model.predict(np.array(X))[-1:]\n",
        "    \n",
        "sentiment = GloveCNNGRUSISentimentModel()\n",
        "history = sentiment.train(X_indices_train, y_train, X_indices_val, y_val)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "seq_input (InputLayer)          (None, 458)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_6 (Embedding)         (None, 458, 50)      250050      seq_input[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 458, 50)      0           embedding_6[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 458, 64)      3264        dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 458, 64)      0           dense_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_3 (Conv1D)               (None, 458, 64)      12352       dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 458, 64)      0           dense_8[0][0]                    \n",
            "                                                                 conv1d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_4 (GlobalM (None, 64)           0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_2 (Bidirectional) (None, 128)          49536       add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "sentiment_by_hidden (Dense)     (None, 1)            65          global_max_pooling1d_4[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "sentiment (Dense)               (None, 1)            129         bidirectional_2[0][0]            \n",
            "==================================================================================================\n",
            "Total params: 315,396\n",
            "Trainable params: 315,396\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Fitting...\n",
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/10\n",
            "25000/25000 [==============================] - 1579s 63ms/step - loss: 0.6020 - sentiment_by_hidden_loss: 0.5352 - sentiment_loss: 0.4950 - sentiment_by_hidden_acc: 0.7292 - sentiment_acc: 0.7383 - val_loss: 0.4098 - val_sentiment_by_hidden_loss: 0.3887 - val_sentiment_loss: 0.3321 - val_sentiment_by_hidden_acc: 0.8300 - val_sentiment_acc: 0.8538\n",
            "Epoch 2/10\n",
            "25000/25000 [==============================] - 1586s 63ms/step - loss: 0.3968 - sentiment_by_hidden_loss: 0.3759 - sentiment_loss: 0.3216 - sentiment_by_hidden_acc: 0.8371 - sentiment_acc: 0.8612 - val_loss: 0.3544 - val_sentiment_by_hidden_loss: 0.3427 - val_sentiment_loss: 0.2858 - val_sentiment_by_hidden_acc: 0.8563 - val_sentiment_acc: 0.8806\n",
            "Epoch 3/10\n",
            "25000/25000 [==============================] - 1575s 63ms/step - loss: 0.3372 - sentiment_by_hidden_loss: 0.3299 - sentiment_loss: 0.2712 - sentiment_by_hidden_acc: 0.8620 - sentiment_acc: 0.8868 - val_loss: 0.3335 - val_sentiment_by_hidden_loss: 0.3190 - val_sentiment_loss: 0.2697 - val_sentiment_by_hidden_acc: 0.8661 - val_sentiment_acc: 0.8875\n",
            "Epoch 4/10\n",
            "25000/25000 [==============================] - 1576s 63ms/step - loss: 0.3079 - sentiment_by_hidden_loss: 0.3031 - sentiment_loss: 0.2472 - sentiment_by_hidden_acc: 0.8758 - sentiment_acc: 0.8981 - val_loss: 0.3202 - val_sentiment_by_hidden_loss: 0.3120 - val_sentiment_loss: 0.2578 - val_sentiment_by_hidden_acc: 0.8701 - val_sentiment_acc: 0.8923\n",
            "Epoch 5/10\n",
            "25000/25000 [==============================] - 1599s 64ms/step - loss: 0.2792 - sentiment_by_hidden_loss: 0.2844 - sentiment_loss: 0.2223 - sentiment_by_hidden_acc: 0.8860 - sentiment_acc: 0.9106 - val_loss: 0.3260 - val_sentiment_by_hidden_loss: 0.3095 - val_sentiment_loss: 0.2641 - val_sentiment_by_hidden_acc: 0.8736 - val_sentiment_acc: 0.8940\n",
            "Epoch 6/10\n",
            "25000/25000 [==============================] - 1599s 64ms/step - loss: 0.2606 - sentiment_by_hidden_loss: 0.2742 - sentiment_loss: 0.2057 - sentiment_by_hidden_acc: 0.8914 - sentiment_acc: 0.9183 - val_loss: 0.3323 - val_sentiment_by_hidden_loss: 0.3177 - val_sentiment_loss: 0.2688 - val_sentiment_by_hidden_acc: 0.8707 - val_sentiment_acc: 0.8906\n",
            "Epoch 7/10\n",
            "25000/25000 [==============================] - 1590s 64ms/step - loss: 0.2376 - sentiment_by_hidden_loss: 0.2579 - sentiment_loss: 0.1861 - sentiment_by_hidden_acc: 0.8975 - sentiment_acc: 0.9270 - val_loss: 0.3456 - val_sentiment_by_hidden_loss: 0.3261 - val_sentiment_loss: 0.2803 - val_sentiment_by_hidden_acc: 0.8722 - val_sentiment_acc: 0.8895\n",
            "Epoch 8/10\n",
            "25000/25000 [==============================] - 1595s 64ms/step - loss: 0.2198 - sentiment_by_hidden_loss: 0.2481 - sentiment_loss: 0.1701 - sentiment_by_hidden_acc: 0.9006 - sentiment_acc: 0.9347 - val_loss: 0.3974 - val_sentiment_by_hidden_loss: 0.3508 - val_sentiment_loss: 0.3272 - val_sentiment_by_hidden_acc: 0.8609 - val_sentiment_acc: 0.8686\n",
            "Epoch 9/10\n",
            "25000/25000 [==============================] - 1595s 64ms/step - loss: 0.2062 - sentiment_by_hidden_loss: 0.2406 - sentiment_loss: 0.1581 - sentiment_by_hidden_acc: 0.9063 - sentiment_acc: 0.9396 - val_loss: 0.3626 - val_sentiment_by_hidden_loss: 0.3251 - val_sentiment_loss: 0.2976 - val_sentiment_by_hidden_acc: 0.8710 - val_sentiment_acc: 0.8911\n",
            "Epoch 10/10\n",
            "25000/25000 [==============================] - 1600s 64ms/step - loss: 0.1981 - sentiment_by_hidden_loss: 0.2370 - sentiment_loss: 0.1507 - sentiment_by_hidden_acc: 0.9062 - sentiment_acc: 0.9420 - val_loss: 0.3471 - val_sentiment_by_hidden_loss: 0.3243 - val_sentiment_loss: 0.2823 - val_sentiment_by_hidden_acc: 0.8716 - val_sentiment_acc: 0.8924\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBr6-9Z--9Td",
        "colab_type": "text"
      },
      "source": [
        "Can we do even better? Yes - let's look at the literature.\n",
        "\n",
        "![image.png](attachment:image.png)\n",
        "\n",
        "...and https://arxiv.org/pdf/1605.07725.pdf (source of table above; 5.91%)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WxfIXq0-9Te",
        "colab_type": "text"
      },
      "source": [
        "Final challenge: What common idea is shared by all of the best models? Can you implement one of them based on what you learned today?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqWwaj-r-9Tf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}